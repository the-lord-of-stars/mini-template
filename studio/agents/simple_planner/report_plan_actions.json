{
    "report_sections": [
        {
            "section_number": 1,
            "section_name": "Executive summary and key takeaways",
            "section_size": "short",
            "section_description": "One-page synthesis of the findings: how automated-visualization (AutoVis) research rose, plateaued or shifted; who the main actors are; what the dominant subtopics and methods are; and three actionable takeaways for researchers. Include a single visual: a one-row sparkline timeline and three bullet metrics (peak year, share of Vis papers, top-cited AutoVis paper).",
            "action": {
                "action": "present",
                "information_needed": {
                    "question_text": "What is the yearly count trend of AutoVis papers (one-row sparkline) and the three headline metrics: (1) peak year (year with maximum AutoVis papers), (2) overall share of AutoVis papers among all Vis papers, and (3) the top-cited AutoVis paper (title, authors, citation count)?",
                    "primary_attributes": [
                        "Year",
                        "AutoVisFlag"
                    ],
                    "secondary_attributes": [
                        "CitationCount_CrossRef",
                        "Title"
                    ],
                    "transformation": [
                        "Label papers as 'AutoVis' using regex on (Title + Abstract + AuthorKeywords) with keywords: automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent (case-insensitive)",
                        "Aggregate counts per Year: count(AutoVis) and count(All Vis papers)",
                        "Compute share_per_year and overall_share = sum(AutoVis_count)/sum(All Vis papers)"
                    ],
                    "expected_insight_types": [
                        "trend",
                        "peak (year)",
                        "proportion/share",
                        "top (most-cited paper)"
                    ]
                }
            }
        },
        {
            "section_number": 2,
            "section_name": "Data and methods (how we identify AutoVis papers)",
            "section_size": "medium",
            "section_description": "Concise description of the dataset, key fields used (Year, Title, Abstract, AuthorKeywords, Citation counts, Downloads, Awards), data cleaning (author de-duplication, affiliation normalization), and the exact AutoVis identification filter/regex (automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent, case-insensitive applied to Title+Abstract+Keywords). Also list derived metrics (normalized citation per year, relative downloads) and planned visual forms. This section ensures reproducibility and lets readers judge the identification approach.",
            "action": {
                "action": "present",
                "information_needed": {
                    "question_text": "How many papers are identified as AutoVis by the specified regex, and how does their count and share evolve over time (per Year)?",
                    "primary_attributes": [
                        "Year",
                        "AutoVis_flag (label produced by regex on Title+Abstract+AuthorKeywords)"
                    ],
                    "secondary_attributes": [
                        "normalized_citations_per_year (CitationCount_CrossRef / (CurrentYear - Year + 1))",
                        "Downloads_Xplore (relative or raw)"
                    ],
                    "transformation": [
                        "Apply case-insensitive regex: /automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/ to (Title + ' ' + Abstract + ' ' + AuthorKeywords) to produce AutoVis_flag ('AutoVis' / 'Other')",
                        "Group by Year and AutoVis_flag to compute counts and proportions",
                        "Compute normalized_citations_per_year = CitationCount_CrossRef / (CurrentYear - Year + 1) and relative_downloads = Downloads_Xplore / max(Downloads_Xplore)"
                    ],
                    "expected_insight_types": [
                        "trend (AutoVis count and share over time)",
                        "distribution (normalized citations and downloads for AutoVis vs Other)",
                        "top (years with highest AutoVis counts)",
                        "outliers (AutoVis papers with unusually high normalized citations or downloads)"
                    ]
                }
            }
        },
        {
            "section_number": 3,
            "section_name": "Temporal trends: rise, fall, and plateaus",
            "section_size": "long",
            "section_description": "Quantitative timeline of AutoVis research: annual counts and proportion of conference/Journal papers labeled AutoVis; cumulative citations over time; burst detection of topic emergence. Visuals: stacked area or line charts showing AutoVis vs other topics, bar chart of first appearance and peak years, and small-multiples for different paper types (J vs C). Include short interpretation of causes for trend changes (tooling, community interest, external drivers).",
            "action": {
                "action": "present",
                "information_needed": {
                    "question_text": "How have AutoVis papers trended over time (annual counts and proportion of all papers), how do their cumulative citations evolve, and how do trends differ between Conference and Journal papers?",
                    "primary_attributes": [
                        "Year",
                        "AutoVis label (AutoVis vs Other)"
                    ],
                    "secondary_attributes": [
                        "PaperType (Conference vs Journal)",
                        "CitationCount_CrossRef (or AminerCitationCount)"
                    ],
                    "transformation": [
                        "Classify papers as 'AutoVis' using the provided keyword regex against Title+Abstract+AuthorKeywords",
                        "Aggregate counts per Year \u00d7 AutoVis label \u00d7 PaperType and compute proportion of AutoVis per year",
                        "Compute cumulative sum of citation counts per year for AutoVis and Other (window transform)"
                    ],
                    "expected_insight_types": [
                        "trend (rise/fall/plateau of annual counts)",
                        "proportion change over time (share of AutoVis)",
                        "comparative trends by PaperType (J vs C)",
                        "cumulative citation growth indicating impact over time",
                        "identify first-appearance and peak year(s) from the annual counts"
                    ]
                }
            }
        },
        {
            "section_number": 4,
            "section_name": "Topic landscape and evolution",
            "section_size": "long",
            "section_description": "Map the conceptual space of AutoVis using keyword co-occurrence, author keywords clustering, and short-term topic drift from Title+Abstract (e.g., recommendation, mixed-initiative, generation, agents). Visuals: network/cluster diagram of keywords, Sankey or alluvial showing how subtopics shift across time windows, and a small heatmap of topic intensity by year. Summarize dominant subtopics, newly-emerging themes, and waning areas.",
            "action": {
                "action": "explore",
                "information_needed": {
                    "question_text": "How do subtopics within Automated Visualization (AutoVis) cluster and evolve over time? In particular, which keyword-based clusters dominate, which subtopics are newly emerging or waning across time windows, and what is the topic intensity per year?",
                    "key_uncertainty": "(1) Whether to rely only on AuthorKeywords or augment them with keywords extracted from Title+Abstract (and how to extract reliably, e.g., unigrams vs. bigrams). (2) What co-occurrence threshold and time-window size produce stable, interpretable clusters and flows for the network/alluvial visualizations. (3) Which number of clusters/topics (k) or community-detection resolution to use for clear labeling.",
                    "expected_outputs": [
                        "A cleaned keyword inventory: deduplicated AuthorKeywords augmented with extracted n-grams (Title+Abstract), stopword- and domain-noise-filtered, with yearly frequencies and the top 30 keywords overall. This will show whether AuthorKeywords suffice or augmentation is needed.",
                        "A co-occurrence edge list (keyword pairs with counts), and a recommended edge-threshold (e.g., edges with count >= 3) plus community-detection assignments (cluster IDs) computed with networkx. Deliverable: suggested set of clusters (labels based on top keywords per cluster) and the parameters used (threshold, algorithm).",
                        "A term-by-time-window matrix using chosen time windows (recommend trying 3-year and 5-year bins). Output: per-cluster/topic counts per window to support an alluvial/Sankey and a year-by-topic heatmap; also a short recommendation of which 6\u20138 topics to visualize (those with highest variance or recent growth) and the preferred window size."
                    ]
                }
            }
        },
        {
            "section_number": 5,
            "section_name": "Influential works, authors and venues",
            "section_size": "medium",
            "section_description": "Identify the AutoVis papers with highest impact (normalized citation, downloads, awards), key authors and their influence (hubs by citations and by collaborative reach), and the venues that published most AutoVis work. Visuals: ranked bar charts for top papers/authors, and a table-like badge for award-winning or highly-downloaded AutoVis papers. Provide short narrations linking influential papers to methodological trends.",
            "action": {
                "action": "present",
                "information_needed": {
                    "question_text": "Which AutoVis papers, authors, and venues have the highest impact after accounting for publication age, downloads, and awards?",
                    "primary_attributes": [
                        "paper: normalized_citations (citation count / age in years)",
                        "author: aggregated_citations (sum of paper citations)"
                    ],
                    "secondary_attributes": [
                        "paper: Downloads_Xplore",
                        "paper: Award / Year / Conference",
                        "author: unique_coauthor_count (collaborative reach)"
                    ],
                    "transformation": [
                        "Filter dataset to AutoVis subset using regex on Title, Abstract, and AuthorKeywords (automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent)",
                        "Compute paper_normalized_citations = max(AminerCitationCount, CitationCount_CrossRef) / (current_year - Year + 1)",
                        "Explode AuthorNames-Deduped to author-level rows; aggregate per author: sum(paper citations) and count(distinct coauthors) to get collaborative reach",
                        "Aggregate per venue (Conference): count(papers) and sum(normalized_citations)"
                    ],
                    "expected_insight_types": [
                        "Top (ranked lists of top papers, top authors, top venues)",
                        "Outliers (papers with unusually high downloads vs. low citations, or award-winning papers with lower citation rates)",
                        "Comparative patterns (authors who are hubs by citations vs. by collaborative reach)"
                    ]
                }
            }
        },
        {
            "section_number": 6,
            "section_name": "Community structure and collaboration patterns",
            "section_size": "medium",
            "section_description": "Analyze co-authorship and institutional collaboration to show how social structure shaped AutoVis research. Visuals: coauthor network with community detection (color clusters), institution collaboration chord or matrix, and timeline of emerging groups. Discuss whether research is concentrated in a few labs or widely distributed, and note cross-disciplinary partnerships.",
            "action": {
                "action": "explore",
                "information_needed": {
                    "question_text": "What are the main co-authorship communities and institution-level collaboration patterns in the AutoVis subset, and how have these communities emerged and changed over time?",
                    "key_uncertainty": "Author name disambiguation and affiliation parsing/normalization (can we reliably map strings to unique authors and canonical institutions); appropriate thresholds for pruning the co\u2011author graph (min publications or min edge weight) so visualizations are readable; which community-detection algorithm and resolution parameter best captures meaningful groups for this dataset.",
                    "expected_outputs": [
                        "A cleaned, deduplicated author list and a normalized institution mapping (rules, examples, and the fraction of records affected). This will resolve whether we can treat AuthorNames-Deduped as sufficient or need additional name disambiguation.",
                        "A co-authorship graph (nodes=authors, weighted edges=coauthorship counts) with chosen pruning parameters (e.g., minimum author degree or top-N authors), plus community-detection output (e.g., Louvain/Leiden clusters), and key graph statistics (nodes, edges, modularity) to guide the network visualization.",
                        "An institution collaboration matrix (institution \u00d7 institution weighted by coauthored papers) and a per-community timeline (yearly counts of publications per detected community). Deliverables: the matrix for a chord/matrix visual, and the yearly series for a stacked/area timeline; include recommended thresholds for institutions to include (e.g., top 20 by collaborations)."
                    ]
                }
            }
        },
        {
            "section_number": 7,
            "section_name": "Representative case studies and research trajectories",
            "section_size": "medium",
            "section_description": "Deep dives (2\u20134 short case studies) of representative AutoVis trajectories: a seminal system/paper, a line of follow-up work, and a contrasting mixed-initiative or agent-driven approach. For each case show timeline of citations, major derivatives (internal references), and role in shifting or stabilizing the field. Use small annotated timelines and citation trees to tell the stories.",
            "action": {
                "action": "explore",
                "information_needed": {
                    "question_text": "Which 2\u20134 representative AutoVis research trajectories should we profile for case studies? Specifically, identify seminal AutoVis papers, their lines of follow-up work (internal derivatives), and at least one contrasting mixed-initiative or agent-driven approach to include.",
                    "key_uncertainty": "I don\u2019t yet know which papers in the dataset match the AutoVis keyword set, which of those have sufficient internal follow-ups (internal references) and citation histories to form a clear trajectory, and what thresholds to use to pick 2\u20134 representative cases.",
                    "expected_outputs": [
                        "A filtered set of papers labeled AutoVis (using the provided keyword regex) with counts: total citations (CitationCount_CrossRef and AminerCitationCount), number of internal citations (times cited by other dataset records via InternalReferences), and number of internal references (how many other dataset records they cite).",
                        "A ranked list of candidate seminal papers (top 10) by a combined score (e.g., weighted Citations + internal-derivative count) and suggested selection of 2\u20134 final case studies meeting criteria (seminal + follow-up depth + diversity: e.g., system-driven vs mixed-initiative/agent).",
                        "For each shortlisted candidate (2\u20134): (a) yearly citation timeline (citations per year derived from CitationCount history if available, or approximated from dataset years of citing papers), (b) an internal citation tree (edges among dataset papers using InternalReferences) showing immediate derivatives and second-level descendants, and (c) short rationale for inclusion."
                    ]
                }
            }
        },
        {
            "section_number": 8,
            "section_name": "Conclusions, open questions and recommendations",
            "section_size": "short",
            "section_description": "Concise synthesis of what happened to AutoVis research, current gaps (evaluation standards, reproducibility, human-centered studies), and concrete recommendations for researchers (datasets, benchmarks, cross-community collaborations). End with pointers to reproducible artifacts: filter code, analysis notebooks, and an interactive dashboard for exploring the dataset.",
            "action": {
                "action": "pend",
                "information_needed": null
            }
        }
    ]
}