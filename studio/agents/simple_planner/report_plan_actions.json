{
    "report_sections": [
        {
            "section_number": 1,
            "section_name": "Executive summary & key takeaways",
            "section_size": "short",
            "section_description": "Concise answer to 'What happened to research on automated visualization?' \u2014 top trends, shifts in activity, and three actionable takeaways for researchers and program chairs.",
            "action": {
                "action": "pend",
                "information_needed": null
            }
        },
        {
            "section_number": 2,
            "section_name": "Data, definitions and methods",
            "section_size": "medium",
            "section_description": "Describe the Vis publication dataset, cleaning steps, the keyword-based AutoVis filter (automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent), other metrics used (citations, downloads, awards, stamp), and planned visual encodings and reproducible code artifacts.",
            "action": {
                "action": "present",
                "information_needed": [
                    {
                        "question_text": "What is the completeness (non-missing coverage) of each dataset attribute so we can describe cleaning needs and potential biases?",
                        "primary_attributes": [
                            "attribute_name"
                        ],
                        "secondary_attributes": [
                            "completeness_rate"
                        ],
                        "transformation": [
                            "compute non-missing count per attribute",
                            "compute completeness_rate = non-missing / total_rows",
                            "sort attributes by completeness_rate descending"
                        ],
                        "expected_insight_types": [
                            "distribution",
                            "outliers (attributes with low completeness)",
                            "ranked list of attributes by coverage"
                        ]
                    },
                    {
                        "question_text": "How many papers are identified as 'AutoVis' by the keyword-based filter versus 'Other', and how do impact metrics (citations and downloads) compare between these groups?",
                        "primary_attributes": [
                            "AutoVis_flag"
                        ],
                        "secondary_attributes": [
                            "count",
                            "median(AminerCitationCount)",
                            "median(Downloads_Xplore)"
                        ],
                        "transformation": [
                            "derive AutoVis_flag using regex test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i) against Title+Abstract+AuthorKeywords",
                            "group by AutoVis_flag",
                            "aggregate count, median citation, median downloads"
                        ],
                        "expected_insight_types": [
                            "comparison (AutoVis vs Other counts)",
                            "central tendency (median citations/downloads)",
                            "outliers (groups with unusually high impact)"
                        ]
                    }
                ]
            }
        },
        {
            "section_number": 3,
            "section_name": "What counts as 'automated visualization' \u2014 taxonomy and examples",
            "section_size": "short",
            "section_description": "Operational taxonomy (recommendation, generation, mixed-initiative, agents, automation in pipeline) with a few exemplar papers from the dataset that match each subtype, clarifying edge cases and limitations of keyword detection.",
            "action": {
                "action": "explore",
                "information_needed": [
                    {
                        "question_text": "For each automated-visualization subtype in the operational taxonomy (recommendation, generation, mixed-initiative, agents, pipeline automation), which papers from the dataset are clear exemplars? (Return a short ranked list per subtype.)",
                        "primary_attributes": [
                            "Title",
                            "Abstract"
                        ],
                        "secondary_attributes": [
                            "Year",
                            "Conference"
                        ],
                        "transformation": [
                            "filter by keyword regex (automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent) applied to Title+Abstract+AuthorKeywords",
                            "group by subtype label inferred from which keyword matched",
                            "rank within each subtype by CitationCount_CrossRef or AminerCitationCount"
                        ],
                        "expected_insight_types": [
                            "top (representative examples per subtype)",
                            "distribution (how many exemplars found per subtype)",
                            "outlier (papers that match multiple subtypes) "
                        ]
                    },
                    {
                        "question_text": "What is the approximate false positive and false negative behavior of the keyword-based detector? (Estimate error modes and exemplar cases to clarify limitations.)",
                        "primary_attributes": [
                            "AuthorKeywords",
                            "Abstract"
                        ],
                        "secondary_attributes": [
                            "Title",
                            "PaperType"
                        ],
                        "transformation": [
                            "take random sample of matched papers (e.g., n=50) and random sample of unmatched papers that look semantically related (n=50)",
                            "manual / rule-based adjudication to label true positive/false positive/false negative"
                        ],
                        "expected_insight_types": [
                            "distribution (estimated false-positive and false-negative rates)",
                            "outliers (typical misleading phrases causing errors)",
                            "examples (concrete paper titles illustrating each error mode) ",
                            "parameters: sample_size_matched=50, sample_size_unmatched=50"
                        ]
                    },
                    {
                        "question_text": "How to present the taxonomy and examples succinctly in a short section (single figure + short table)? (Design metrics for a compact figure.)",
                        "primary_attributes": [
                            "subtype_label"
                        ],
                        "secondary_attributes": [
                            "count_of_matched_papers",
                            "top_example_title"
                        ],
                        "transformation": [
                            "aggregate counts per subtype from keyword matches",
                            "select top 1\u20133 exemplars per subtype by citation count"
                        ],
                        "expected_insight_types": [
                            "distribution (counts per subtype)",
                            "top (1\u20133 exemplar titles per subtype)",
                            "edge cases noted in captions ",
                            "parameters: top_examples_per_subtype=3"
                        ]
                    }
                ]
            }
        },
        {
            "section_number": 4,
            "section_name": "Temporal trends and venue distribution",
            "section_size": "long",
            "section_description": "Year-by-year counts and share of AutoVis vs Other papers (line/area charts), breakdown by conference (InfoVis, VAST, SciVis etc.), burst detection (where activity peaks/declines), and a short timeline of milestone papers. Visuals: stacked area, small multiples, annotated peaks.",
            "action": {
                "action": "present",
                "information_needed": [
                    {
                        "question_text": "How has the yearly count and share of AutoVis vs Other papers changed over time, and where are the largest activity peaks or bursts?",
                        "primary_attributes": [
                            "Year",
                            "Category (AutoVis vs Other)"
                        ],
                        "secondary_attributes": [
                            "Count / Share"
                        ],
                        "transformation": [
                            "Classify each paper as 'AutoVis' or 'Other' using the keyword filter: test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, (datum.AuthorKeywords || '') + ' ' + (datum.Abstract || '') + ' ' + (datum.Title || '')) ? 'AutoVis' : 'Other'",
                            "Aggregate: count papers per Year \u00d7 Category",
                            "Compute share per year (AutoVis count / total count) and year-over-year growth rates",
                            "Detect bursts where year-over-year growth > 50% OR absolute increase >= 5 papers (parameterizable)"
                        ],
                        "expected_insight_types": [
                            "trend",
                            "share over time",
                            "peaks/bursts",
                            "relative growth/decline",
                            "timing of major shifts or inflection points of AutoVis activity."
                        ]
                    },
                    {
                        "question_text": "How do temporal trends of AutoVis (counts and share) differ across major venues (conferences)?",
                        "primary_attributes": [
                            "Year",
                            "Conference"
                        ],
                        "secondary_attributes": [
                            "Category (AutoVis vs Other)",
                            "Count or Share"
                        ],
                        "transformation": [
                            "Select top N conferences by total paper count (parameter N = 5) to keep small multiples readable (e.g., InfoVis, VAST, SciVis, EuroVis, PacificVis/CHI if present)",
                            "For each selected conference, aggregate counts per Year \u00d7 Category and compute yearly share of AutoVis",
                            "Optionally apply a 3-year rolling average to smooth noisy year-to-year variation",
                            "Flag and annotate conference-specific bursts using same burst rule as above"
                        ],
                        "expected_insight_types": [
                            "trend (per-venue)",
                            "comparison between venues",
                            "identification of venue-specific peaks or declines",
                            "outlier years where a conference shows unusually high AutoVis activity."
                        ]
                    }
                ]
            }
        },
        {
            "section_number": 5,
            "section_name": "Topic evolution and content analysis",
            "section_size": "medium",
            "section_description": "Keyword and abstract-based topic analysis to show how research themes within AutoVis shifted over time (e.g., rule-based recommendation \u2192 ML-driven generation \u2192 mixed-initiative agents). Visuals: evolving word clouds, topic timelines, representative abstracts for each period.",
            "action": {
                "action": "explore",
                "information_needed": [
                    {
                        "question_text": "How did the prevalence of predefined AutoVis themes (rule-based recommendation, ML-driven generation, mixed-initiative agents, visualization toolkits, and evaluation/narrative) change over time (yearly or multi-year periods)?",
                        "primary_attributes": [
                            "Year"
                        ],
                        "secondary_attributes": [
                            "Theme (rule-based, ML-driven, mixed-initiative, toolkit, evaluation/narrative)"
                        ],
                        "transformation": [
                            "Text normalization (lowercase, remove punctuation, stopwords) on Title+Abstract+AuthorKeywords",
                            "Rule-based keyword matching using domain keywords to assign papers to one or more themes (e.g., 'visualization recommendation', 'automatic vis', 'automated vis', 'visualization generation', 'vis generation' \u2192 recommendation/generation; 'machine learning', 'deep learning', 'neural' \u2192 ML-driven; 'mixed initiative', 'mixed-initiative', 'agent' \u2192 mixed-initiative; 'toolkit', 'library', 'D3' \u2192 toolkit; 'narrative', 'evaluation', 'user study' \u2192 evaluation/narrative)",
                            "Aggregate counts/proportions of papers per theme by Year or by multi-year bins (e.g., 3-year windows)"
                        ],
                        "expected_insight_types": [
                            "trend (increase/decrease of themes over time)",
                            "top (which themes dominate particular periods)",
                            "shift (emergence or decline of themes)",
                            "co-occurrence patterns across themes over time (multi-theme papers) "
                        ]
                    },
                    {
                        "question_text": "What latent topics emerge from abstracts (via topic modeling) and how do their relative proportions evolve over time?",
                        "primary_attributes": [
                            "Year"
                        ],
                        "secondary_attributes": [
                            "Topic (latent)",
                            "Topic prevalence per paper"
                        ],
                        "transformation": [
                            "Preprocess abstracts (tokenize, lemmatize, remove stopwords and rare/high-frequency terms)",
                            "Fit LDA/NMF with K topics (discover latent topics)",
                            "Label topics by top terms and map each paper to topic distribution",
                            "Aggregate average topic proportions per Year or per multi-year bins"
                        ],
                        "expected_insight_types": [
                            "trend (topic proportion trajectories)",
                            "top (most prominent topics overall and per period)",
                            "change points (when a topic gains/loses prominence)",
                            "representative examples (top-scoring abstracts per topic and period)",
                            "outlier topics that spike briefly]",
                            "parameters\":{\"K_topics\":6,\"time_bin\":\"year or 3-year\",\"top_terms_per_topic\":10,\"representative_per_topic_per_period\":3}}]} (Note: the second item's expected_insight_types field intentionally includes multiple insight types and the parameters object for the topic-modeling plan.)}unctuation-free-json-invalid-summary-fixed{",
                            "information_needed_signature_end}",
                            "description_end"
                        ]
                    }
                ]
            }
        },
        {
            "section_number": 6,
            "section_name": "Impact and community structure",
            "section_size": "long",
            "section_description": "Citation and usage analysis (Aminer / CrossRef / Xplore), award and replicability-stamp signals, plus social structure: co-author network, institution contributions, and diffusion of ideas across subcommunities. Visuals: citation histograms, network graphs, choropleth or affiliation bar charts.",
            "action": {
                "action": "explore",
                "information_needed": [
                    {
                        "question_text": "What is the citation / usage distribution of papers in the dataset and which papers are clear outliers (high-impact)?",
                        "primary_attributes": [
                            "AminerCitationCount"
                        ],
                        "secondary_attributes": [
                            "Year",
                            "Conference"
                        ],
                        "transformation": [
                            "log10(AminerCitationCount + 1)",
                            "filter by Year range (optional)",
                            "bin for histogram (e.g., 40 bins)"
                        ],
                        "expected_insight_types": [
                            "distribution",
                            "outlier",
                            "top items",
                            "trend by year (if Year used)",
                            "venue differences (if Conference used)"
                        ]
                    },
                    {
                        "question_text": "What is the co-author social structure: who are the most central authors and what subcommunities (clusters) exist?",
                        "primary_attributes": [
                            "AuthorNames-Deduped (as node id)"
                        ],
                        "secondary_attributes": [
                            "Year (for temporal slices)",
                            "Conference or PaperType (to color/label clusters)"
                        ],
                        "transformation": [
                            "explode AuthorNames-Deduped into author list per paper",
                            "generate all undirected coauthor pairs per paper",
                            "aggregate edge weights (co-authorship counts)",
                            "filter to top N authors by degree or edge-weight (e.g., top 100)",
                            "run community detection / compute degree and betweenness centrality"
                        ],
                        "expected_insight_types": [
                            "network structure",
                            "top (most central) authors",
                            "clusters / communities",
                            "temporal changes (if Year used)",
                            "bridge authors connecting communities"
                        ]
                    },
                    {
                        "question_text": "Which institutions (and countries) contribute the most papers and citations, and how is contribution distributed geographically?",
                        "primary_attributes": [
                            "AuthorAffiliation (parsed to institution / country)"
                        ],
                        "secondary_attributes": [
                            "AminerCitationCount or CitationCount_CrossRef (to weight impact)",
                            "Year"
                        ],
                        "transformation": [
                            "parse AuthorAffiliation to extract institution and country",
                            "explode affiliations per paper and assign fractional paper credit per author (optional)",
                            "aggregate counts and sum citation metrics by institution/country",
                            "rank and take top K (e.g., top 20)"
                        ],
                        "expected_insight_types": [
                            "top institutions/countries",
                            "distribution of contributions",
                            "impact-weighted ranking (citations per institution)",
                            "trends over time (if Year used)"
                        ]
                    }
                ]
            }
        },
        {
            "section_number": 7,
            "section_name": "Case studies and narratives",
            "section_size": "medium",
            "section_description": "Deep dives into 3\u20134 influential/representative works (methods, reception, downstream influence) illustrating how approaches matured or stalled, and how tooling/community shaped follow-up research.",
            "action": {
                "action": "explore",
                "information_needed": [
                    {
                        "question_text": "Which 3\u20134 papers in the dataset that match the 'automated visualization' keyword set are the most influential and representative candidates for case studies? (Use combined influence metrics to rank candidates.)",
                        "primary_attributes": [
                            "Title",
                            "Year",
                            "CitationCount_CrossRef",
                            "AminerCitationCount"
                        ],
                        "secondary_attributes": [
                            "Downloads_Xplore",
                            "Award",
                            "AuthorKeywords"
                        ],
                        "transformation": [
                            "filter rows matching automated-visualization keywords in Title/Abstract/AuthorKeywords using regex",
                            "normalize citation and download metrics and compute a combined influence score",
                            "rank papers by combined score and select top_n"
                        ],
                        "expected_insight_types": [
                            "top",
                            "outlier",
                            "distribution across years and venues (to check representativeness)",
                            "presence of awards or reproducibility stamps as qualifiers for selection."
                        ]
                    },
                    {
                        "question_text": "For each selected candidate paper, what is its downstream influence within this dataset over time as measured by internal citations (occurrences of its DOI in other papers' InternalReferences) and how does that compare to its general citation counts?",
                        "primary_attributes": [
                            "Year",
                            "count_internal_references_per_year"
                        ],
                        "secondary_attributes": [
                            "CitationCount_CrossRef",
                            "AminerCitationCount",
                            "Title"
                        ],
                        "transformation": [
                            "explode InternalReferences to one DOI per row",
                            "match target paper DOI and aggregate counts by citing paper Year",
                            "merge with target paper's yearly citation totals if available (or use overall citation counts)"
                        ],
                        "expected_insight_types": [
                            "trend",
                            "growth",
                            "lag (time from publication to peak citations)",
                            "comparison between internal-network influence and external citation counts."
                        ]
                    }
                ]
            }
        },
        {
            "section_number": 8,
            "section_name": "Conclusions, limitations and recommendations",
            "section_size": "short",
            "section_description": "Synthesize findings, highlight dataset and method limitations (keyword false positives/negatives, venue coverage), and propose concrete next steps for the research community (evaluation benchmarks, shared datasets, replications, program committee suggestions).",
            "action": {
                "action": "pend",
                "information_needed": null
            }
        }
    ]
}