<!DOCTYPE html>
<html lang='en'>
<head>
  <meta charset='utf-8'>
  <meta name='viewport' content='width=device-width, initial-scale=1.0'>
  <title>Research Report: Automated Visualization</title>
  <script src='https://cdn.jsdelivr.net/npm/vega@5'></script>
  <script src='https://cdn.jsdelivr.net/npm/vega-lite@5'></script>
  <script src='https://cdn.jsdelivr.net/npm/vega-embed@6'></script>
  <script src='https://cdn.tailwindcss.com'></script>
  <script>
    tailwind.config = {
      theme: {
        extend: {
          typography: ({ theme }) => ({
            DEFAULT: { css: { color: theme('colors.gray.800') } }
          })
        }
      }
    }
  </script>
</head>
<body class='bg-white text-gray-800'>
  <div id='progress-bar' class='fixed top-0 left-0 h-1 bg-black z-[9999]' style='width:0%'></div>  <nav class='sticky top-0 bg-white border-b border-gray-200 z-50'>
    <div class='w-[95%] mx-auto px-6 py-3 flex justify-between items-center'>
      <a href='#' class='font-bold text-lg'>Agentic VIS Report</a>
      <div class='hidden md:flex items-center space-x-10 text-sm'>
        <a href='https://www.visagent.org/' target='_blank' class='hover:text-primary-600 text-lg'>Challenge</a>
        <a href='https://github.com/the-lord-of-stars/mini-template' target='_blank'>
          <img src='https://cdnjs.cloudflare.com/ajax/libs/simple-icons/9.16.0/github.svg' alt='GitHub' class='w-6 h-6'>
        </a>
      </div>
      <button id='menu-btn' class='md:hidden flex items-center focus:outline-none'>
        <svg xmlns='http://www.w3.org/2000/svg' class='w-6 h-6' fill='none' viewBox='0 0 24 24' stroke='currentColor'>
          <path stroke-linecap='round' stroke-linejoin='round' stroke-width='2' d='M4 6h16M4 12h16M4 18h16' />
        </svg>
      </button>
    </div>
    <div id='mobile-menu' class='hidden md:hidden bg-white border-t border-gray-200'>
      <div class='px-6 py-3 flex flex-col space-y-4'>
        <a href='https://www.visagent.org/' target='_blank' class='hover:text-primary-600 text-lg'>Official Challenge Website</a>
        <a href='https://github.com/the-lord-of-stars/mini-template' target='_blank' class='flex items-center space-x-4'>
          <img src='https://cdnjs.cloudflare.com/ajax/libs/simple-icons/9.16.0/github.svg' alt='GitHub' class='w-6 h-6'>
          <span class='text-lg'>Project GitHub Repo</span>
        </a>
      </div>
    </div>
  </nav>
  <script>
    const btn = document.getElementById('menu-btn');
    const menu = document.getElementById('mobile-menu');
    btn.addEventListener('click', () => { menu.classList.toggle('hidden'); });
  </script>
  <nav class='hidden lg:block fixed top-20 left-6 w-[15%] h-[80vh] overflow-y-auto
               p-4 text-sm'
       aria-label='Table of contents'>
    <h2 class='font-semibold text-gray-900 mb-3'>Table of contents</h2>
    <ol id='toc-list' class='space-y-2'></ol>
  </nav>
  <main class='w-[90%] max-w-3xl mx-auto px-6 py-12 lg:w-[75%] lg:ml-[20%] lg:max-w-none lg:mx-0'>
    <header class='text-center mb-12'>
      <h1 class='text-4xl font-bold text-gray-900 mb-4'>What happened to research on automated visualization?</h1>
       <p class='text-lg text-gray-600'>Generated on 2025-08-21 </p>
    </header>
    <article class='prose prose-lg prose-gray'>
<section class='mb-16'>
  <h2 class='text-3xl font-bold mb-6 border-b border-gray-200 pb-2'>
    1. Executive summary
  </h2>
  <div class='space-y-10'>
    <div class='prose prose-lg prose-gray max-w-none'>
      <p class="text-gray-700 leading-relaxed mb-4">Automated visualization (AutoVis) is a small but persistent strand within the Vis corpus: 83 AutoVis papers were detected out of 3,877 total (≈2.1%). The field has not collapsed but neither has it exploded — a gentle long-term upward slope in share (slope ≈ 0.002 share-per-year) but large year-to-year fluctuations and concentrated bursts (notably 2016, 2020, a pronounced peak in 2021 with 16 papers / 14.7% share, and another high point in 2023 with 12 papers / 9.0% share). A handful of high-impact systems papers (for example Voyager, Draco, and foundational task/design work) account for much of AutoVis’s citation footprint, while most authors contribute one or a few papers each. From these patterns we draw three high-level recommendations: (1) prioritize artifact and code release to amplify the community impact of systems work, (2) broaden and standardize evaluation practices (more user studies and shared benchmarks), and (3) program committees should explicitly reward reproducibility and interdisciplinary work to sustain healthy growth rather than ephemeral hype cycles.</p>
    </div>
    <div class='my-8'>
      <div class='bg-gray-50 rounded-lg shadow-sm p-4'>
        <p class='text-red-600'>Error loading visualization</p>
        <p class='text-sm text-gray-600 mt-2 text-center'>
          <p class="text-gray-700 leading-relaxed mb-4">The prevalence chart pairs yearly counts (bars) with a line showing AutoVis share of that year’s papers. It makes clear that AutoVis activity is intermittent: no detected AutoVis papers in many early years, first appearances in the mid-1990s, and modest upward momentum since about 2014. Over the full window there are 83 AutoVis papers out of 3,877 total. Peak activity occurred in 2021 (16 AutoVis papers, 14.7% of that year), with other notable increases in 2016 (6 papers, 5.2%) and 2020 (7 papers, 4.5%). The share line highlights how rare AutoVis work typically is — most years under 4% — and how single busy years can dominate the story. The fitted trend is slightly positive, but the year-to-year volatility warns against reading a simple steady rise: AutoVis appears to surge episodically rather than grow smoothly.</p>
        </p>
      </div>
    </div>
    <div class='my-8'>
      <div class='bg-gray-50 rounded-lg shadow-sm p-4'>
        <div class='mb-4 flex justify-center overflow-x-auto'>
          <div style='width: 100%;'>
            <div id='vis-1-2'></div>
          </div>
        </div>
        <script>
          vegaEmbed('#vis-1-2', {"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "description": "Find the top-cited AutoVis paper (using keywords in Title/Abstract/AuthorKeywords). Shows the top 1 AutoVis paper by CrossRef citation count with tooltip details.", "data": {"url": "https://raw.githubusercontent.com/demoPlz/mini-template/main/studio/dataset.csv", "format": {"type": "csv"}}, "transform": [{"calculate": "test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, (datum.AuthorKeywords || '') + ' ' + (datum.Abstract || '') + ' ' + (datum.Title || '')) ? 'AutoVis' : 'Other'", "as": "AutoVis"}, {"calculate": "toNumber(datum.CitationCount_CrossRef)", "as": "CitationCount"}, {"filter": "datum.AutoVis === 'AutoVis'"}, {"window": [{"op": "rank", "as": "rank"}], "sort": [{"field": "CitationCount", "order": "descending"}]}, {"filter": "datum.rank <= 1"}], "mark": {"type": "bar", "tooltip": true}, "encoding": {"y": {"field": "Title", "type": "nominal", "axis": {"title": "Title"}}, "x": {"field": "CitationCount", "type": "quantitative", "axis": {"title": "CitationCount_CrossRef"}}, "color": {"field": "Conference", "type": "nominal", "legend": {"title": "Conference"}}, "tooltip": [{"field": "Title", "type": "nominal", "title": "Title"}, {"field": "AuthorNames", "type": "nominal", "title": "Authors"}, {"field": "Year", "type": "ordinal", "title": "Year"}, {"field": "Conference", "type": "nominal", "title": "Conference"}, {"field": "CitationCount", "type": "quantitative", "title": "CitationCount_CrossRef"}]}, "width": 640, "height": 120, "title": "Top AutoVis paper by CrossRef citations (top 1)"}, {
            actions: false,
            renderer: 'canvas',
            config: {}
          })
          .catch(console.error);
        </script>
        <p class='text-sm text-gray-600 mt-2 text-center'>
          <p class="text-gray-700 leading-relaxed mb-4">The top-paper panel isolates the single most-cited AutoVis contribution by CrossRef citations: Voyager (2015, InfoVis) stands out with 292 CrossRef citations and is also the leading entry when using Aminer counts (487). A small group of papers concentrates influence: Draco (2018) and A Design Space of Visualization Tasks (2013) follow Voyager as highly cited AutoVis works. Across the 83 AutoVis papers the median citation is 14 and the mean around 30, indicating a skewed distribution where a few landmark systems drive the average; most AutoVis papers have modest citation counts.</p>
        </p>
      </div>
    </div>
  </div>
</section>
<section class='mb-16'>
  <h2 class='text-3xl font-bold mb-6 border-b border-gray-200 pb-2'>
    2. Data and methods: how we identify AutoVis
  </h2>
  <div class='space-y-10'>
    <div class='prose prose-lg prose-gray max-w-none'>
      <p class="text-gray-700 leading-relaxed mb-4">Our dataset is the Vis corpus (3,877 records), with fields including Year, Title, Abstract, AuthorKeywords, AuthorNames, DOI, Conference, and multiple citation/download metrics (Aminer, CrossRef, Downloads_Xplore). We labelled AutoVis papers using an explicit keyword filter applied to Title + Abstract + AuthorKeywords (terms such as "automatic vis", "automated vis", "visualization recommendation", "mixed initiative" / "mixed-initiative", "visualization generation", "vis generation", and "agent"). Preprocessing included deduplication by DOI/Title (keeping the most recent record), normalizing affiliation/author strings, and creating derived fields: AutoVis flag (binary), Year, Conference, citation counts (CrossRef/Aminer) and download counts. We also applied optional time-window filters for focused analyses; for example, restricting to 2000–2020 reduces the corpus to 2,670 records and yields 41 AutoVis papers in that window. The labeling strategy favors precision (explicit keywords) at the cost of missing implicitly related work, so we recommend combining keyword rules with manual review or topic-based augmentation for broader recall.</p>
    </div>
    <div class='my-8'>
      <div class='bg-gray-50 rounded-lg shadow-sm p-4'>
        <div class='mb-4 flex justify-center overflow-x-auto'>
          <div style='width: 100%;'>
            <div id='vis-2-1'></div>
          </div>
        </div>
        <script>
          vegaEmbed('#vis-2-1', {"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "description": "Counts of papers at each pipeline step (raw, dedup, time-window) with AutoVis vs Other breakdown. Use the start/end year controls to change the time-window filter.", "params": [{"name": "startYear", "value": 2000, "bind": {"input": "number", "min": 1900, "max": 2030, "step": 1}}, {"name": "endYear", "value": 2020, "bind": {"input": "number", "min": 1900, "max": 2030, "step": 1}}], "hconcat": [{"title": "1) Raw dataset", "width": 200, "height": 240, "data": {"url": "https://raw.githubusercontent.com/demoPlz/mini-template/main/studio/dataset.csv"}, "transform": [{"calculate": "test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, (datum['AuthorKeywords'] || '') + ' ' + (datum['Abstract'] || '') + ' ' + (datum['Title'] || '')) ? 'AutoVis' : 'Other'", "as": "AutoVis"}, {"aggregate": [{"op": "count", "as": "count"}], "groupby": ["AutoVis"]}], "mark": "bar", "encoding": {"x": {"field": "AutoVis", "type": "nominal", "axis": {"labelAngle": 0}}, "y": {"field": "count", "type": "quantitative", "title": "Number of papers"}, "color": {"field": "AutoVis", "type": "nominal", "legend": null}, "tooltip": [{"field": "AutoVis", "type": "nominal"}, {"field": "count", "type": "quantitative"}]}}, {"title": "2) After de-duplication (by DOI/Title)", "width": 200, "height": 240, "data": {"url": "https://raw.githubusercontent.com/demoPlz/mini-template/main/studio/dataset.csv"}, "transform": [{"calculate": "(datum.DOI || '') + '|' + (datum.Title || '')", "as": "_key"}, {"window": [{"op": "row_number", "as": "rn"}], "groupby": ["_key"], "sort": [{"field": "Year", "order": "descending"}]}, {"filter": "datum.rn === 1"}, {"calculate": "test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, (datum['AuthorKeywords'] || '') + ' ' + (datum['Abstract'] || '') + ' ' + (datum['Title'] || '')) ? 'AutoVis' : 'Other'", "as": "AutoVis"}, {"aggregate": [{"op": "count", "as": "count"}], "groupby": ["AutoVis"]}], "mark": "bar", "encoding": {"x": {"field": "AutoVis", "type": "nominal", "axis": {"labelAngle": 0}}, "y": {"field": "count", "type": "quantitative", "title": "Number of papers"}, "color": {"field": "AutoVis", "type": "nominal", "legend": null}, "tooltip": [{"field": "AutoVis", "type": "nominal"}, {"field": "count", "type": "quantitative"}]}}, {"title": "3) After time-window filter (deduped + year range)", "width": 200, "height": 240, "data": {"url": "https://raw.githubusercontent.com/demoPlz/mini-template/main/studio/dataset.csv"}, "transform": [{"calculate": "(datum.DOI || '') + '|' + (datum.Title || '')", "as": "_key"}, {"window": [{"op": "row_number", "as": "rn"}], "groupby": ["_key"], "sort": [{"field": "Year", "order": "descending"}]}, {"filter": "datum.rn === 1"}, {"filter": "datum.Year >= startYear && datum.Year <= endYear"}, {"calculate": "test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, (datum['AuthorKeywords'] || '') + ' ' + (datum['Abstract'] || '') + ' ' + (datum['Title'] || '')) ? 'AutoVis' : 'Other'", "as": "AutoVis"}, {"aggregate": [{"op": "count", "as": "count"}], "groupby": ["AutoVis"]}], "mark": "bar", "encoding": {"x": {"field": "AutoVis", "type": "nominal", "axis": {"labelAngle": 0}}, "y": {"field": "count", "type": "quantitative", "title": "Number of papers"}, "color": {"field": "AutoVis", "type": "nominal", "legend": null}, "tooltip": [{"field": "AutoVis", "type": "nominal"}, {"field": "count", "type": "quantitative"}]}}, {"title": "4) After keyword labelling (deduped + time-window; labelled AutoVis vs Other)", "width": 200, "height": 240, "data": {"url": "https://raw.githubusercontent.com/demoPlz/mini-template/main/studio/dataset.csv"}, "transform": [{"calculate": "(datum.DOI || '') + '|' + (datum.Title || '')", "as": "_key"}, {"window": [{"op": "row_number", "as": "rn"}], "groupby": ["_key"], "sort": [{"field": "Year", "order": "descending"}]}, {"filter": "datum.rn === 1"}, {"filter": "datum.Year >= startYear && datum.Year <= endYear"}, {"calculate": "test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, (datum['AuthorKeywords'] || '') + ' ' + (datum['Abstract'] || '') + ' ' + (datum['Title'] || '')) ? 'AutoVis' : 'Other'", "as": "AutoVis"}, {"aggregate": [{"op": "count", "as": "count"}], "groupby": ["AutoVis"]}], "mark": "bar", "encoding": {"x": {"field": "AutoVis", "type": "nominal", "axis": {"labelAngle": 0}}, "y": {"field": "count", "type": "quantitative", "title": "Number of papers"}, "color": {"field": "AutoVis", "type": "nominal", "legend": null}, "tooltip": [{"field": "AutoVis", "type": "nominal"}, {"field": "count", "type": "quantitative"}]}}], "config": {"view": {"continuousHeight": 240}}}, {
            actions: false,
            renderer: 'canvas',
            config: {}
          })
          .catch(console.error);
        </script>
        <p class='text-sm text-gray-600 mt-2 text-center'>
          <p class="text-gray-700 leading-relaxed mb-4">The filtering pipeline visualization walks through counts at each stage: the raw dataset (3,877 records, 83 AutoVis hits), deduplication (no change here because duplicates were rare), and an example time-window filter (2000–2020) that reduces the corpus to 2,670 papers and 41 AutoVis matches. A final column shows the “retained only AutoVis” view (41 papers) to emphasize how small the AutoVis subset is within a practical window. This display reinforces two practical points: (1) simple keyword labelling is effective for identifying a high-precision AutoVis set, and (2) time-window choices materially affect what we count — several AutoVis peaks fall outside arbitrary windows and should be handled carefully when reporting trends.</p>
        </p>
      </div>
    </div>
  </div>
</section>
<section class='mb-16'>
  <h2 class='text-3xl font-bold mb-6 border-b border-gray-200 pb-2'>
    3. Temporal trends: volume, prominence, and lifecycle
  </h2>
  <div class='space-y-10'>
    <div class='prose prose-lg prose-gray max-w-none'>
      <p class="text-gray-700 leading-relaxed mb-4">Looking across time, AutoVis shows episodic bursts rather than smooth, sustained growth. Raw counts rise from sporadic early occurrences to noticeable activity after 2013, with major spikes in 2016, 2020, 2021, and 2023. Impact metrics move in complementary ways: Aminer and CrossRef citations and Xplore downloads for AutoVis papers have generally positive recent slopes (AutoVis Aminer slope ≈ +1.88 on yearly means; CrossRef slope positive as well), while downloads show large spikes for particular years and papers. Medians show that AutoVis papers’ typical citation level (median ≈14) sits close to other Vis work, but a few high-impact systems substantially raise AutoVis averages. Topic-life analyses using 3-year windows reveal a long history of topic births and deaths, with sustained introductions in many windows and an especially active recent windowing period — suggesting both churn and episodic consolidation in AutoVis-related themes.</p>
    </div>
    <div class='my-8'>
      <div class='bg-gray-50 rounded-lg shadow-sm p-4'>
        <div class='mb-4 flex justify-center overflow-x-auto'>
          <div style='width: 100%;'>
            <div id='vis-3-1'></div>
          </div>
        </div>
        <script>
          vegaEmbed('#vis-3-1', {"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "data": {"url": "https://raw.githubusercontent.com/demoPlz/mini-template/main/studio/dataset.csv", "format": {"type": "csv"}}, "concat": [{"width": 420, "height": 320, "transform": [{"calculate": "(/(automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent)/i).test((datum.AuthorKeywords || '') + ' ' + (datum.Abstract || '') + ' ' + (datum.Title || '')) ? 'AutoVis' : 'Other'", "as": "Category"}], "mark": "bar", "encoding": {"x": {"field": "Year", "type": "ordinal", "axis": {"title": "Year", "labelAngle": 0}, "sort": "ascending"}, "y": {"aggregate": "count", "type": "quantitative", "axis": {"title": "Number of papers"}}, "color": {"field": "Category", "type": "nominal", "legend": {"title": "Category"}}, "tooltip": [{"field": "Year", "type": "ordinal"}, {"field": "Category", "type": "nominal"}, {"aggregate": "count", "type": "quantitative", "title": "Count"}]}}, {"width": 420, "height": 320, "transform": [{"calculate": "(/(automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent)/i).test((datum.AuthorKeywords || '') + ' ' + (datum.Abstract || '') + ' ' + (datum.Title || '')) ? 'AutoVis' : 'Other'", "as": "Category"}, {"aggregate": [{"op": "count", "as": "count"}], "groupby": ["Year", "Category"]}, {"joinaggregate": [{"op": "sum", "field": "count", "as": "year_total"}], "groupby": ["Year"]}, {"calculate": "datum.count / datum.year_total", "as": "share"}], "mark": "bar", "encoding": {"x": {"field": "Year", "type": "ordinal", "axis": {"title": "Year", "labelAngle": 0}, "sort": "ascending"}, "y": {"field": "count", "type": "quantitative", "stack": "normalize", "axis": {"title": "Share of papers", "format": ".0%"}}, "color": {"field": "Category", "type": "nominal", "legend": null}, "tooltip": [{"field": "Year", "type": "ordinal"}, {"field": "Category", "type": "nominal"}, {"field": "count", "type": "quantitative", "title": "Count"}, {"field": "share", "type": "quantitative", "title": "Share", "format": ".1%"}]}}], "title": "Annual volume and share of AutoVis papers vs Other", "resolve": {"scale": {"color": "shared"}}}, {
            actions: false,
            renderer: 'canvas',
            config: {}
          })
          .catch(console.error);
        </script>
        <p class='text-sm text-gray-600 mt-2 text-center'>
          <p class="text-gray-700 leading-relaxed mb-4">The annual-volume + share view juxtaposes absolute counts (stacked/grouped bars) with a normalized share panel so the reader sees both how many AutoVis papers appeared and how large a slice they occupied each year. The plot underlines three patterns: long stretches of zero AutoVis activity in the 1990s; modest but steady presence from ~2014 onward; and sharp peaks in 2016, 2020 and especially 2021 (16 papers, 14.7%). The normalized share view is particularly revealing: a small count in a low-volume year can produce a large share, and vice versa, so interpreting raw counts without context would be misleading. The most recent years (2023: 12 papers, 9.0%; 2024: 7 papers, 5.6%) show renewed interest but not a sustained exponential trend.</p>
        </p>
      </div>
    </div>
    <div class='my-8'>
      <div class='bg-gray-50 rounded-lg shadow-sm p-4'>
        <div class='mb-4 flex justify-center overflow-x-auto'>
          <div style='width: 100%;'>
            <div id='vis-3-2'></div>
          </div>
        </div>
        <script>
          vegaEmbed('#vis-3-2', {"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "description": "Trends of mean and median citation/download metrics over time for AutoVis vs Other (3-year centered smoothing).", "data": {"url": "https://raw.githubusercontent.com/demoPlz/mini-template/main/studio/dataset.csv"}, "transform": [{"calculate": "test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, (datum.AuthorKeywords || '') + ' ' + (datum.Abstract || '') + ' ' + (datum.Title || '')) ? 'AutoVis' : 'Other'", "as": "Category"}, {"fold": ["AminerCitationCount", "CitationCount_CrossRef", "Downloads_Xplore"], "as": ["Metric", "Value"]}, {"aggregate": [{"op": "mean", "field": "Value", "as": "mean"}, {"op": "median", "field": "Value", "as": "median"}], "groupby": ["Year", "Category", "Metric"]}, {"fold": ["mean", "median"], "as": ["Stat", "AggValue"]}, {"window": [{"op": "mean", "field": "AggValue", "as": "smoothed"}], "frame": [-1, 1], "groupby": ["Category", "Metric", "Stat"], "sort": [{"field": "Year", "order": "ascending"}]}], "facet": {"column": {"field": "Metric", "type": "nominal", "header": {"labelAngle": 0, "title": "Metric"}}}, "spec": {"width": 260, "height": 160, "mark": {"type": "line", "point": true, "interpolate": "monotone"}, "encoding": {"x": {"field": "Year", "type": "ordinal", "title": "Year"}, "y": {"field": "smoothed", "type": "quantitative", "title": "Metric value (3-year centered mean)"}, "color": {"field": "Category", "type": "nominal", "scale": {"scheme": "category10"}, "title": "Category"}, "strokeDash": {"field": "Stat", "type": "nominal", "scale": {"domain": ["mean", "median"], "range": [[], [4, 2]]}, "title": "Statistic"}, "tooltip": [{"field": "Year", "type": "ordinal", "title": "Year"}, {"field": "Category", "type": "nominal", "title": "Category"}, {"field": "Metric", "type": "nominal", "title": "Metric"}, {"field": "Stat", "type": "nominal", "title": "Statistic"}, {"field": "AggValue", "type": "quantitative", "title": "Aggregated value (raw)"}, {"field": "smoothed", "type": "quantitative", "title": "Smoothed value"}]}}, "config": {"axis": {"labelFontSize": 11, "titleFontSize": 12}, "legend": {"labelFontSize": 11, "titleFontSize": 12}}}, {
            actions: false,
            renderer: 'canvas',
            config: {}
          })
          .catch(console.error);
        </script>
        <p class='text-sm text-gray-600 mt-2 text-center'>
          <p class="text-gray-700 leading-relaxed mb-4">The metrics-timeseries panel compares mean/median citation and download indicators across AutoVis and Other papers with a 3-year centered smoothing. Key takeaways: AutoVis shows an increasing trend in Aminer citation means (slope ≈ +1.88) even while the Other category’s Aminer means decline in recent years; CrossRef citation means for AutoVis also trend upward (slope ≈ +0.87) and downloads for AutoVis grow faster than Other (AutoVis downloads slope ≈ +55.15, recent mean ≈ 451). The series also reveal volatile year-over-year spikes (examples include large YoY jumps around 2013 and 2015 for citations and a number of download spikes in 2013 and 2018). Together these signals imply that while most AutoVis papers attract modest attention, well-timed systems work can rapidly amplify community visibility via both citations and downloads.</p>
        </p>
      </div>
    </div>
    <div class='my-8'>
      <div class='bg-gray-50 rounded-lg shadow-sm p-4'>
        <div class='mb-4 flex justify-center overflow-x-auto'>
          <div style='width: 100%;'>
            <div id='vis-3-3'></div>
          </div>
        </div>
        <script>
          vegaEmbed('#vis-3-3', {"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "description": "Rolling-window birth/death counts of 'AutoVis' topics. Topics are derived preferentially from AuthorKeywords-Deduped (fallback to AuthorKeywords). Papers are filtered to those matching AutoVis-related terms. Windows are non-overlapping fixed-size bins (window size = 3 years). Birth = topic's first window; Death = topic's last window. Suggested parameters (editable in transform calculates): windowSize=3, minPapers=2, persistence=2.", "data": {"url": "https://raw.githubusercontent.com/demoPlz/mini-template/main/studio/dataset.csv", "format": {"type": "csv"}}, "transform": [{"calculate": "datum['AuthorKeywords-Deduped'] || datum.AuthorKeywords || ''", "as": "rawKeywords"}, {"calculate": "lower(datum.rawKeywords)", "as": "keywords_lc"}, {"calculate": "replace(datum.keywords_lc, /[,;]+/g, ';')", "as": "keywords_norm"}, {"calculate": "split(datum.keywords_norm, ';')", "as": "topic_tokens"}, {"flatten": ["topic_tokens"], "as": "topic_raw"}, {"calculate": "trim(topic_raw)", "as": "topic"}, {"filter": "datum.topic !== null && datum.topic !== ''"}, {"calculate": "test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, (datum['AuthorKeywords'] || '') + ' ' + (datum.Abstract || '') + ' ' + (datum.Title || '')) ? 'AutoVis' : 'Other'", "as": "paperClass"}, {"filter": "datum.paperClass === 'AutoVis'"}, {"joinaggregate": [{"op": "min", "field": "Year", "as": "minYear"}, {"op": "max", "field": "Year", "as": "maxYear"}]}, {"calculate": "3", "as": "windowSize"}, {"calculate": "2", "as": "minPapers"}, {"calculate": "2", "as": "persistenceWindows"}, {"calculate": "floor((toNumber(datum.Year) - datum.minYear) / datum.windowSize)", "as": "windowIndex"}, {"calculate": "datum.minYear + datum.windowIndex * datum.windowSize", "as": "windowStart"}, {"calculate": "(datum.windowStart) + '-' + (datum.windowStart + datum.windowSize - 1)", "as": "windowLabel"}, {"joinaggregate": [{"op": "min", "field": "windowIndex", "as": "firstWindow"}, {"op": "max", "field": "windowIndex", "as": "lastWindow"}], "groupby": ["topic"]}, {"aggregate": [{"op": "count", "as": "papersCount"}], "groupby": ["topic", "windowIndex", "windowStart", "windowLabel", "firstWindow", "lastWindow", "minYear", "maxYear", "windowSize", "minPapers", "persistenceWindows"]}, {"calculate": "(datum.firstWindow === datum.windowIndex && datum.papersCount >= datum.minPapers) ? 1 : 0", "as": "isBirth"}, {"calculate": "(datum.lastWindow === datum.windowIndex && datum.papersCount >= datum.minPapers) ? 1 : 0", "as": "isDeath"}, {"aggregate": [{"op": "sum", "field": "isBirth", "as": "births"}, {"op": "sum", "field": "isDeath", "as": "deaths"}, {"op": "count", "field": "topic", "as": "topics_present"}], "groupby": ["windowIndex", "windowStart", "windowLabel"]}, {"calculate": "datum.windowStart", "as": "xYear"}, {"calculate": "toNumber(datum.windowIndex)", "as": "xIndex"}], "layer": [{"mark": {"type": "line", "point": true, "interpolate": "monotone"}, "encoding": {"x": {"field": "xYear", "type": "quantitative", "title": "Window start year (window size = 3 years)", "axis": {"format": "d"}}, "y": {"field": "births", "type": "quantitative", "title": "Count"}, "color": {"value": "#1f77b4"}, "tooltip": [{"field": "windowLabel", "type": "nominal", "title": "Window"}, {"field": "births", "type": "quantitative", "title": "Births"}, {"field": "deaths", "type": "quantitative", "title": "Deaths"}, {"field": "topics_present", "type": "quantitative", "title": "Topics present"}]}}, {"mark": {"type": "line", "point": true, "interpolate": "monotone"}, "encoding": {"x": {"field": "xYear", "type": "quantitative"}, "y": {"field": "deaths", "type": "quantitative"}, "color": {"value": "#d62728"}}}, {"mark": {"type": "bar", "opacity": 0.25}, "encoding": {"x": {"field": "xYear", "type": "quantitative"}, "y": {"field": "topics_present", "type": "quantitative"}, "color": {"value": "#2ca02c"}, "opacity": {"value": 0.25}}}], "resolve": {"scale": {"y": "independent"}}, "title": "AutoVis topic lifecycle (births & deaths) across 3-year windows\n(Topics from AuthorKeywords; windows = fixed 3-year bins; minPapers=2)"}, {
            actions: false,
            renderer: 'canvas',
            config: {}
          })
          .catch(console.error);
        </script>
        <p class='text-sm text-gray-600 mt-2 text-center'>
          <p class="text-gray-700 leading-relaxed mb-4">The topic-lifecycle visualization groups topics extracted from AuthorKeywords (fallback to normalized tokens from Title/Abstract) into non-overlapping 3-year windows, then counts topic births and deaths (birth = first window meeting a minimum-paper threshold; death = last window followed by persistence windows without presence). Parameters used here were windowSize=3 years, minPapers=2, persistenceWindows=2 to reduce noise. The analysis produced a large set of derived topics (9,0XX) with clear top terms ("visual analytics", "visualization", "information visualization", "volume rendering", etc.). Birth counts show sustained topic introduction across decades, with particularly high birth activity in many windows and recent windows (window starts at 2021 and 2022 show many births; note later-window deaths are zero by construction because future windows are missing). This lifecycle view highlights sustained churn: AutoVis themes frequently emerge, some persist and consolidate, while many are short-lived or absorbed into broader visualization topics.</p>
        </p>
      </div>
    </div>
  </div>
</section>
<section class='mb-16'>
  <h2 class='text-3xl font-bold mb-6 border-b border-gray-200 pb-2'>
    4. Who shaped AutoVis: authors, institutions, and collaboration networks
  </h2>
  <div class='space-y-10'>
    <div class='prose prose-lg prose-gray max-w-none'>
      <p class="text-gray-700 leading-relaxed mb-4">To understand who shaped AutoVis we analyzed authorship and affiliations, computing paper counts, an h-like rank per author (based on their AutoVis papers’ citations), aggregate citations, and simple centrality proxies in co-authorship networks. The set is authorially diffuse: 83 AutoVis papers involve 311 unique authors with a median of one AutoVis paper per author. A small set of researchers and groups produce multiple contributions and accumulate most citations — a common pattern in systems-oriented subfields where a few labs produce influential toolkits while many contributors publish one-off studies.</p>
    </div>
    <div class='my-8'>
      <div class='bg-gray-50 rounded-lg shadow-sm p-4'>
        <div class='mb-4 flex justify-center overflow-x-auto'>
          <div style='width: 100%;'>
            <div id='vis-4-1'></div>
          </div>
        </div>
        <script>
          vegaEmbed('#vis-4-1', {"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "description": "Top AutoVis authors by productivity (paper count). Bars show number of AutoVis papers per author; color encodes aggregate citations (CitationCount_CrossRef fallback AminerCitationCount). Tooltip includes h-like rank and citation list.", "data": {"url": "https://raw.githubusercontent.com/demoPlz/mini-template/main/studio/dataset.csv"}, "transform": [{"calculate": "split(datum['AuthorNames-Deduped'] || '', ';')", "as": "authors"}, {"flatten": ["authors"]}, {"calculate": "trim(datum.authors || '')", "as": "author"}, {"filter": "datum.author != ''"}, {"filter": "test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, (datum.AuthorKeywords || '') + ' ' + (datum.Abstract || '') + ' ' + (datum.Title || ''))"}, {"calculate": "(!isNaN(+datum.CitationCount_CrossRef) ? +datum.CitationCount_CrossRef : (!isNaN(+datum.AminerCitationCount) ? +datum.AminerCitationCount : 0))", "as": "citations"}, {"aggregate": [{"op": "count", "as": "paper_count"}, {"op": "values", "field": "citations", "as": "citations_list"}, {"op": "sum", "field": "citations", "as": "total_citations"}], "groupby": ["author"]}, {"calculate": "(function(arr){arr=(arr||[]).map(function(x){return +x}).sort(function(a,b){return b-a}); for(var i=0;i<arr.length;i++){ if(arr[i] < i+1) return i;} return arr.length})(datum.citations_list)", "as": "h_like"}, {"window": [{"op": "rank", "as": "rank_papers"}], "sort": [{"field": "paper_count", "order": "descending"}]}, {"filter": "datum.rank_papers <= 20"}], "width": 800, "height": 600, "mark": {"type": "bar", "tooltip": true}, "encoding": {"x": {"field": "paper_count", "type": "quantitative", "title": "Number of AutoVis papers (productivity)"}, "y": {"field": "author", "type": "nominal", "title": "Author", "sort": {"field": "paper_count", "op": "max", "order": "descending"}}, "color": {"field": "total_citations", "type": "quantitative", "title": "Aggregate citations", "scale": {"scheme": "blues"}}, "tooltip": [{"field": "author", "type": "nominal", "title": "Author"}, {"field": "paper_count", "type": "quantitative", "title": "Paper count"}, {"field": "total_citations", "type": "quantitative", "title": "Total citations"}, {"field": "h_like", "type": "quantitative", "title": "h-like rank"}, {"field": "citations_list", "type": "ordinal", "title": "Citations per paper (list)"}]}, "title": "Top AutoVis Authors: Productivity vs Aggregate Citations (top 20 by paper count)"}, {
            actions: false,
            renderer: 'canvas',
            config: {}
          })
          .catch(console.error);
        </script>
        <p class='text-sm text-gray-600 mt-2 text-center'>
          <p class="text-gray-700 leading-relaxed mb-4">The author-productivity chart ranks the top authors by number of AutoVis papers and encodes aggregate citations. It shows that a handful of authors are relatively prolific: Alex Endert leads with 7 AutoVis papers (total citations ≈ 436), Yingcai Wu and Huamin Qu each have 6 papers, and Jeffrey Heer appears with 5 papers but the largest aggregate citation total (≈551). The visualization exposes a familiar divergence: productivity is not identical to citation impact — some authors with few papers (e.g., Kanit Wongsuphasawat, Jock Mackinlay, Anushka Anand) have very high per-paper influence because of landmark contributions like Voyager. At the same time several productive authors have modest average citations, underscoring heterogeneity in author impact profiles.</p>
        </p>
      </div>
    </div>
    <div class='my-8'>
      <div class='bg-gray-50 rounded-lg shadow-sm p-4'>
        <div class='mb-4 flex justify-center overflow-x-auto'>
          <div style='width: 100%;'>
            <div id='vis-4-2'></div>
          </div>
        </div>
        <script>
          vegaEmbed('#vis-4-2', {"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "description": "Exploratory multi-panel view to support choosing thresholds and identifying central authors for AutoVis co-authorship networks. Left: cumulative authors remaining if we keep authors with >= min papers (use this to pick min_papers_per_author to reach ~200 nodes). Right-top: scatter of per-author paper_count vs coauthor_sum (proxy degree) for sizing/coloring decisions. Bottom: top-10 authors by coauthor_sum as suggested gatekeepers / ego seeds.", "data": {"url": "https://raw.githubusercontent.com/demoPlz/mini-template/main/studio/dataset.csv"}, "vconcat": [{"title": "Cumulative number of authors vs min_papers_per_author (choose threshold to keep ~200 nodes)", "width": 700, "height": 220, "transform": [{"filter": "test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, (datum['AuthorKeywords'] || '') + ' ' + (datum.Abstract || '') + ' ' + (datum.Title || ''))"}, {"calculate": "max(0, length(split(datum['AuthorNames-Deduped'] || '', ';')) - 1)", "as": "coauthors"}, {"calculate": "split(datum['AuthorNames-Deduped'] || '', ';')", "as": "authors"}, {"flatten": ["authors"], "as": ["author"]}, {"calculate": "trim(datum.author)", "as": "author"}, {"aggregate": [{"op": "count", "as": "paper_count"}, {"op": "sum", "field": "coauthors", "as": "coauthor_sum"}], "groupby": ["author"]}, {"aggregate": [{"op": "count", "as": "authors_at_count"}], "groupby": ["paper_count"]}, {"sort": [{"field": "paper_count", "order": "descending"}]}, {"window": [{"op": "sum", "field": "authors_at_count", "as": "cumulative_authors"}]}], "layer": [{"mark": {"type": "area", "interpolate": "step-after", "opacity": 0.25, "color": "#4C78A8"}, "encoding": {"x": {"field": "paper_count", "type": "quantitative", "title": "min_papers_per_author (paper_count)"}, "y": {"field": "cumulative_authors", "type": "quantitative", "title": "Number of authors with >= threshold"}, "tooltip": [{"field": "paper_count", "type": "quantitative", "title": "paper_count (threshold)"}, {"field": "authors_at_count", "type": "quantitative", "title": "authors with this paper_count"}, {"field": "cumulative_authors", "type": "quantitative", "title": "cumulative authors (>=)"}]}}, {"mark": {"type": "line", "interpolate": "step-after", "color": "#2E8B57"}, "encoding": {"x": {"field": "paper_count", "type": "quantitative"}, "y": {"field": "cumulative_authors", "type": "quantitative"}}}, {"mark": {"type": "rule", "color": "red", "strokeDash": [4, 2]}, "encoding": {"y": {"datum": 200, "type": "quantitative"}}}, {"mark": {"type": "text", "align": "left", "dx": 4, "dy": -8, "color": "red"}, "encoding": {"x": {"value": 1}, "y": {"datum": 200, "type": "quantitative"}, "text": {"value": "target ~200 authors (suggested node budget)"}}}]}, {"title": "Per-author proxy centrality: paper_count vs coauthor_sum (proxy degree)", "width": 700, "height": 340, "transform": [{"filter": "test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, (datum['AuthorKeywords'] || '') + ' ' + (datum.Abstract || '') + ' ' + (datum.Title || ''))"}, {"calculate": "max(0, length(split(datum['AuthorNames-Deduped'] || '', ';')) - 1)", "as": "coauthors"}, {"calculate": "split(datum['AuthorNames-Deduped'] || '', ';')", "as": "authors"}, {"flatten": ["authors"], "as": ["author"]}, {"calculate": "trim(datum.author)", "as": "author"}, {"aggregate": [{"op": "count", "as": "paper_count"}, {"op": "sum", "field": "coauthors", "as": "coauthor_sum"}, {"op": "max", "field": "AuthorKeywords", "as": "sample_keyword"}], "groupby": ["author"]}], "mark": {"type": "circle", "opacity": 0.8, "stroke": "#222"}, "encoding": {"x": {"field": "paper_count", "type": "quantitative", "title": "paper_count (papers by author)", "scale": {"zero": true}}, "y": {"field": "coauthor_sum", "type": "quantitative", "title": "sum of (coauthors per paper) \u2014 proxy degree", "scale": {"zero": true}}, "size": {"field": "coauthor_sum", "type": "quantitative", "legend": {"title": "proxy degree (size)"}, "scale": {"range": [30, 1200]}}, "color": {"field": "sample_keyword", "type": "nominal", "legend": {"title": "sample_keyword (first listed)"}}, "tooltip": [{"field": "author", "type": "nominal", "title": "author"}, {"field": "paper_count", "type": "quantitative", "title": "paper_count"}, {"field": "coauthor_sum", "type": "quantitative", "title": "proxy degree"}, {"field": "sample_keyword", "type": "nominal", "title": "sample_keyword"}]}}, {"title": "Top 10 candidate gatekeepers (authors with highest proxy degree)", "width": 700, "height": 240, "transform": [{"filter": "test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, (datum['AuthorKeywords'] || '') + ' ' + (datum.Abstract || '') + ' ' + (datum.Title || ''))"}, {"calculate": "max(0, length(split(datum['AuthorNames-Deduped'] || '', ';')) - 1)", "as": "coauthors"}, {"calculate": "split(datum['AuthorNames-Deduped'] || '', ';')", "as": "authors"}, {"flatten": ["authors"], "as": ["author"]}, {"calculate": "trim(datum.author)", "as": "author"}, {"aggregate": [{"op": "count", "as": "paper_count"}, {"op": "sum", "field": "coauthors", "as": "coauthor_sum"}, {"op": "max", "field": "AuthorAffiliation", "as": "sample_affiliation"}], "groupby": ["author"]}, {"window": [{"op": "rank", "as": "rank"}], "sort": [{"field": "coauthor_sum", "order": "descending"}]}, {"filter": "datum.rank <= 10"}, {"calculate": "datum.rank + '. ' + datum.author + ' \u2014 papers: ' + datum.paper_count + ', proxy_degree: ' + datum.coauthor_sum + (datum.sample_affiliation ? (' (affil: ' + datum.sample_affiliation + ')') : '')", "as": "label"}], "mark": {"type": "text", "align": "left", "baseline": "middle", "dx": 3}, "encoding": {"y": {"field": "rank", "type": "ordinal", "axis": null}, "x": {"value": 5}, "text": {"field": "label", "type": "nominal"}, "tooltip": [{"field": "author", "type": "nominal", "title": "author"}, {"field": "paper_count", "type": "quantitative", "title": "paper_count"}, {"field": "coauthor_sum", "type": "quantitative", "title": "proxy_degree"}, {"field": "sample_affiliation", "type": "nominal", "title": "sample_affiliation"}]}}], "config": {"axis": {"labelFontSize": 11, "titleFontSize": 12}, "legend": {"labelFontSize": 11, "titleFontSize": 12}}}, {
            actions: false,
            renderer: 'canvas',
            config: {}
          })
          .catch(console.error);
        </script>
        <p class='text-sm text-gray-600 mt-2 text-center'>
          <p class="text-gray-700 leading-relaxed mb-4">The co-authorship exploration panel helps choose pruning thresholds for a force-directed network and identifies candidate gatekeepers (high proxy-degree authors). The cumulative-author curve shows how raising the minimum papers-per-author dramatically reduces node counts (a practical knob to reach a desired node budget — recommended min_papers_per_author=2 retains ~68 nodes). The scatter of paper_count vs coauthor_sum gives a proxy for centrality: authors with many collaborators and multiple papers stand out as natural seeds for ego networks. Based on these heuristics, recommended gatekeepers include Yingcai Wu, Weiwei Cui, and Haidong Zhang; community detection over the pruned network yields about two dozen communities (several moderate-sized groups and many small ones). Practical visualization parameters are suggested (edge weights = coauthorship counts, node size = paper_count^0.6, prune edges with weight <2) to make interactive network layouts interpretable.</p>
        </p>
      </div>
    </div>
  </div>
</section>
<section class='mb-16'>
  <h2 class='text-3xl font-bold mb-6 border-b border-gray-200 pb-2'>
    5. What was studied: topical themes and methodological shifts
  </h2>
  <div class='space-y-10'>
    <div class='prose prose-lg prose-gray max-w-none'>
      <p class="text-gray-700 leading-relaxed mb-4">The topical analysis of AutoVis material reveals a small set of recurring themes: visualization recommendation and automated design (recommendation engines and generative layout/design systems), mixed-initiative and interactive generation, automation targeted at specific tasks (e.g., chart suggestions or story generation), and evaluation-focused work (benchmarks, user studies). Methodologically, much AutoVis work is systems- or algorithm-centered (simulation/algorithmic contributions), while user studies and qualitative evaluation occur but less frequently. Theme trajectories suggest that recommendation/generation work has become better articulated since the mid-2010s and often appears in InfoVis and VAST venues; however, many theme instances are short-lived and occasionally absorbed back into broader visualization research rather than forming a sustained, distinct subcommunity.</p>
    </div>
  </div>
</section>
<section class='mb-16'>
  <h2 class='text-3xl font-bold mb-6 border-b border-gray-200 pb-2'>
    6. Influence and reproducibility: citations, downloads, awards, and artifacts
  </h2>
  <div class='space-y-10'>
    <div class='prose prose-lg prose-gray max-w-none'>
      <p class="text-gray-700 leading-relaxed mb-4">We measured influence using multiple proxies — CrossRef and Aminer citation counts, Xplore downloads, awards, and a GraphicsReplicabilityStamp that serves as a crude artifact indicator. AutoVis includes a few high-impact, widely cited systems (Voyager, Draco, Design Space work), but the set lacks observable replicability stamps or consistent artifact release: among the top AutoVis items no paper in our top lists had a graphics replicability stamp recorded, and across the AutoVis subset the GraphicsReplicabilityStamp field is effectively empty. Citations and downloads are positively correlated (log-log correlation r ≈ 0.63), meaning well-cited work tends also to be well-downloaded, but many AutoVis papers achieve visibility primarily through a small number of influential systems rather than broad artifact-driven replication.</p>
    </div>
    <div class='my-8'>
      <div class='bg-gray-50 rounded-lg shadow-sm p-4'>
        <div class='mb-4 flex justify-center overflow-x-auto'>
          <div style='width: 100%;'>
            <div id='vis-6-1'></div>
          </div>
        </div>
        <script>
          vegaEmbed('#vis-6-1', {"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "description": "Scatter plot of log10(CitationCount_CrossRef + 1) vs log10(Downloads_Xplore + 1). Points are colored by whether they match AutoVis keywords, shaped by Award, and sized by AminerCitationCount. Tooltip shows key metadata.", "data": {"url": "https://raw.githubusercontent.com/demoPlz/mini-template/main/studio/dataset.csv"}, "transform": [{"filter": "isFinite(datum.CitationCount_CrossRef) && isFinite(datum.Downloads_Xplore) && datum.CitationCount_CrossRef != null && datum.Downloads_Xplore != null"}, {"calculate": "test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, (datum.AuthorKeywords || '') + ' ' + (datum.Abstract || '') + ' ' + (datum.Title || '')) ? 'AutoVis' : 'Other'", "as": "AutoVis_flag"}, {"calculate": "log(datum.CitationCount_CrossRef + 1) / log(10)", "as": "Citation_log"}, {"calculate": "log(datum.Downloads_Xplore + 1) / log(10)", "as": "Downloads_log"}], "width": 700, "height": 520, "mark": {"type": "point", "filled": true, "opacity": 0.8, "stroke": "#222"}, "encoding": {"x": {"field": "Citation_log", "type": "quantitative", "title": "Log10(CitationCount_CrossRef + 1)", "axis": {"grid": true}}, "y": {"field": "Downloads_log", "type": "quantitative", "title": "Log10(Downloads_Xplore + 1)", "axis": {"grid": true}}, "color": {"field": "AutoVis_flag", "type": "nominal", "title": "AutoVis flag", "scale": {"range": ["#1f77b4", "#d62728"]}}, "shape": {"field": "Award", "type": "nominal", "title": "Award"}, "size": {"field": "AminerCitationCount", "type": "quantitative", "title": "AminerCitationCount", "scale": {"range": [30, 450]}}, "tooltip": [{"field": "Title", "type": "nominal", "title": "Title"}, {"field": "AuthorNames", "type": "nominal", "title": "Authors"}, {"field": "CitationCount_CrossRef", "type": "quantitative", "title": "Citations (CrossRef)"}, {"field": "Downloads_Xplore", "type": "quantitative", "title": "Downloads (Xplore)"}, {"field": "AminerCitationCount", "type": "quantitative", "title": "AminerCitationCount"}, {"field": "AutoVis_flag", "type": "nominal", "title": "AutoVis_flag"}, {"field": "Award", "type": "nominal", "title": "Award"}, {"field": "Year", "type": "nominal", "title": "Year"}]}, "config": {"legend": {"titleFontSize": 12, "labelFontSize": 11}, "axis": {"labelFontSize": 11, "titleFontSize": 12}}}, {
            actions: false,
            renderer: 'canvas',
            config: {}
          })
          .catch(console.error);
        </script>
        <p class='text-sm text-gray-600 mt-2 text-center'>
          <p class="text-gray-700 leading-relaxed mb-4">The citations-vs-downloads scatterplot shows a clear positive relationship (log–log correlation r ≈ 0.632) indicating that, across the corpus, papers that attract citations tend to be downloaded more. Most high-citation, high-download landmarks are not AutoVis papers (e.g., D³ and UpSet), but a few AutoVis systems (Voyager) sit near the top-right of the AutoVis cluster. The plot also highlights outliers: some papers receive disproportionately many downloads relative to citations and vice versa. For AutoVis specifically, the correlation suggests that releasing useful artifacts and accessible demos is likely to increase both downloads and downstream citations.</p>
        </p>
      </div>
    </div>
    <div class='my-8'>
      <div class='bg-gray-50 rounded-lg shadow-sm p-4'>
        <div class='mb-4 flex justify-center overflow-x-auto'>
          <div style='width: 100%;'>
            <div id='vis-6-2'></div>
          </div>
        </div>
        <script>
          vegaEmbed('#vis-6-2', {"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "description": "Top AutoVis papers (landmarks) by combined score of citations and downloads. Color indicates presence of awards; a triangle mark indicates presence of a graphics/replicability artifact.", "data": {"url": "https://raw.githubusercontent.com/demoPlz/mini-template/main/studio/dataset.csv"}, "transform": [{"calculate": "(datum.AuthorKeywords || '') + ' ' + (datum.Abstract || '') + ' ' + (datum.Title || '')", "as": "_combined_text"}, {"calculate": "test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, datum._combined_text)", "as": "AutoVis_flag"}, {"filter": "datum.AutoVis_flag"}, {"calculate": "toNumber(datum.AminerCitationCount)", "as": "AminerCitation"}, {"calculate": "toNumber(datum.Downloads_Xplore)", "as": "Downloads"}, {"calculate": "(datum.Award || '') != ''", "as": "award_flag"}, {"calculate": "(datum.GraphicsReplicabilityStamp || '') != ''", "as": "replicability_flag"}, {"joinaggregate": [{"op": "max", "field": "AminerCitation", "as": "max_cite"}, {"op": "max", "field": "Downloads", "as": "max_download"}]}, {"calculate": "datum.max_cite == 0 ? 0 : datum.AminerCitation / datum.max_cite", "as": "AminerCitation_norm"}, {"calculate": "datum.max_download == 0 ? 0 : datum.Downloads / datum.max_download", "as": "Downloads_norm"}, {"calculate": "(datum.AminerCitation_norm * 0.7) + (datum.Downloads_norm * 0.3)", "as": "combined_score"}, {"window": [{"op": "rank", "as": ["rank"]}], "sort": [{"field": "combined_score", "order": "descending"}]}, {"filter": "datum.rank <= 10"}], "layer": [{"mark": {"type": "bar", "cornerRadius": 4}, "encoding": {"x": {"field": "combined_score", "type": "quantitative", "title": "Combined score (norm citations 70% + downloads 30%)"}, "y": {"field": "Title", "type": "nominal", "title": "Title", "sort": {"field": "combined_score", "order": "descending"}}, "color": {"field": "award_flag", "type": "nominal", "title": "Award?", "scale": {"domain": [true, false], "range": ["#d95f02", "#6baed6"]}, "legend": {"orient": "right"}}, "tooltip": [{"field": "Title", "type": "nominal"}, {"field": "Year", "type": "ordinal"}, {"field": "AminerCitation", "type": "quantitative", "title": "AminerCitationCount"}, {"field": "Downloads", "type": "quantitative", "title": "Downloads_Xplore"}, {"field": "Award", "type": "nominal"}, {"field": "GraphicsReplicabilityStamp", "type": "nominal", "title": "Replicability stamp"}, {"field": "DOI", "type": "nominal", "title": "DOI"}, {"field": "Link", "type": "nominal", "title": "Link"}]}}, {"transform": [{"filter": "datum.replicability_flag"}], "mark": {"type": "point", "filled": true, "shape": "triangle", "size": 180, "opacity": 0.95}, "encoding": {"x": {"field": "combined_score", "type": "quantitative"}, "y": {"field": "Title", "type": "nominal", "sort": {"field": "combined_score", "order": "descending"}}, "color": {"value": "#31a354"}, "tooltip": [{"field": "Title", "type": "nominal"}, {"field": "Year", "type": "ordinal"}, {"field": "AminerCitation", "type": "quantitative"}, {"field": "Downloads", "type": "quantitative"}, {"field": "GraphicsReplicabilityStamp", "type": "nominal"}]}}], "width": 760, "height": 420, "config": {"axis": {"labelLimit": 300}, "view": {"stroke": "transparent"}}}, {
            actions: false,
            renderer: 'canvas',
            config: {}
          })
          .catch(console.error);
        </script>
        <p class='text-sm text-gray-600 mt-2 text-center'>
          <p class="text-gray-700 leading-relaxed mb-4">The ranked land-marks panel combines normalized citation and download measures to surface the top AutoVis contributions by a blended score (70% citations, 30% downloads). Voyager (2015) ranks highest by far, followed by A Design Space of Visualization Tasks and Draco (2018). Of the top ten AutoVis landmarks in this combined ranking, only two list an award and none show a recorded GraphicsReplicabilityStamp in the dataset — a concrete signal that artifact release and formal replicability recognition remain rare among the most influential AutoVis works. This reinforces an actionable target for the community: encouraging artifact availability for high-impact systems would likely improve reproducibility and reuse.</p>
        </p>
      </div>
    </div>
    <div class='my-8'>
      <div class='bg-gray-50 rounded-lg shadow-sm p-4'>
        <div class='mb-4 flex justify-center overflow-x-auto'>
          <div style='width: 100%;'>
            <div id='vis-6-3'></div>
          </div>
        </div>
        <script>
          vegaEmbed('#vis-6-3', {"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "description": "Distribution of GraphicsReplicabilityStamp among AutoVis papers (filtered by keywords in Title/Abstract/AuthorKeywords). Faceted by Award status (Has award: Yes/No) and colored by PaperType (J/C).", "data": {"url": "https://raw.githubusercontent.com/demoPlz/mini-template/main/studio/dataset.csv", "format": {"type": "csv"}}, "transform": [{"calculate": "test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, (datum.AuthorKeywords || '') + ' ' + (datum.Abstract || '') + ' ' + (datum.Title || ''))", "as": "AutoVis_flag"}, {"filter": "datum.AutoVis_flag"}, {"calculate": "(datum.GraphicsReplicabilityStamp || '') == '' ? 'None' : datum.GraphicsReplicabilityStamp", "as": "GraphicsReplicabilityStamp_norm"}, {"calculate": "(datum.Award || '') == '' ? 'No' : 'Yes'", "as": "HasAward"}], "facet": {"row": {"field": "HasAward", "type": "nominal", "title": "Award winner?", "header": {"labelFontSize": 12}}}, "spec": {"width": 320, "height": 220, "mark": {"type": "bar", "cornerRadius": 2}, "encoding": {"x": {"field": "GraphicsReplicabilityStamp_norm", "type": "nominal", "axis": {"title": "Graphics Replicability Stamp (normalized)"}}, "y": {"aggregate": "count", "type": "quantitative", "axis": {"title": "Number of AutoVis papers"}}, "color": {"field": "PaperType", "type": "nominal", "title": "Paper Type", "legend": {"orient": "top"}}, "tooltip": [{"field": "GraphicsReplicabilityStamp_norm", "type": "nominal", "title": "Replicability stamp"}, {"field": "PaperType", "type": "nominal", "title": "Paper type"}, {"aggregate": "count", "type": "quantitative", "title": "Count"}]}}, "title": "Graphics Replicability Stamp Distribution for AutoVis Papers (faceted by award status)"}, {
            actions: false,
            renderer: 'canvas',
            config: {}
          })
          .catch(console.error);
        </script>
        <p class='text-sm text-gray-600 mt-2 text-center'>
          <p class="text-gray-700 leading-relaxed mb-4">The replicability-stamp distribution for AutoVis is stark: nearly every AutoVis paper in the set has no GraphicsReplicabilityStamp recorded (83/83 = 100% in the extraction). When faceted by award status or paper type this absence is consistent. Practically, this means the community cannot rely on the dataset’s replicability field to find released artifacts and must resort to manual checks (DOI/links, project pages, or code repositories). The visualization therefore underscores a clear community gap: to increase practical reuse and verification of AutoVis systems, authors and venues should adopt consistent artifact badges or require explicit artifact links.</p>
        </p>
      </div>
    </div>
  </div>
</section>
<section class='mb-16'>
  <h2 class='text-3xl font-bold mb-6 border-b border-gray-200 pb-2'>
    7. Interpretation, open questions, and community recommendations
  </h2>
  <div class='space-y-10'>
    <div class='prose prose-lg prose-gray max-w-none'>
      <p class="text-gray-700 leading-relaxed mb-4">Has automated visualization waned, plateaued, or been absorbed? The evidence points to plateauing with episodic resurgences and partial absorption into broader Vis themes. The long-term slope of AutoVis proportion is small and positive but below our threshold for declaring clear growth, and year-to-year volatility — especially the 2021 spike and 2022 drop — suggests interest comes in pulses often sparked by influential systems. Impact concentrates in a few landmark papers rather than a broad body of consistently high-impact contributions. To move forward the community should (1) incentivize artifact and code release and make replicability stamps standard; (2) encourage more rigorous and diverse evaluations (more user studies, shared benchmarks); (3) fund and reward interdisciplinary collaborations that pair systems expertise with domain evaluation; (4) ask program committees to explicitly prioritize reproducibility, artifact availability, and balanced review criteria for AutoVis submissions; and (5) build shared datasets and challenges to create steady, comparable progress rather than one-off bursts.</p>
    </div>
    <div class='my-8'>
      <div class='bg-gray-50 rounded-lg shadow-sm p-4'>
        <p class='text-red-600'>Error loading visualization</p>
        <p class='text-sm text-gray-600 mt-2 text-center'>
          <p class="text-gray-700 leading-relaxed mb-4">The prevalence-and-median panel in the recommendations section ties proportion of AutoVis papers to median AutoVis citations over time: AutoVis proportion remains low overall (2.14% across the corpus), with a small positive slope that we interpret as plateauing rather than robust growth. Median AutoVis citations hover near those of other papers (AutoVis median ≈14 vs Other ≈15 overall) and do not show steady, outsized advantage. The figure also highlights dramatic single-year deviations (2021’s +10.2% spike and 2022’s −10.5% drop) which likely reflect a few concentrated publication clusters rather than durable expansion. Taken together, the chart motivates the report’s five prioritized recommendations and a short roadmap: adopt artifact policies and badges, invest in shared benchmarks and evaluation standards, and create venues or tracks to sustain reproducible, interdisciplinary AutoVis research over the next five years.</p>
        </p>
      </div>
    </div>
    <div class='my-8'>
      <div class='bg-gray-50 rounded-lg shadow-sm p-4'>
        <div class='mb-4 flex justify-center overflow-x-auto'>
          <div style='width: 100%;'>
            <div id='vis-7-2'></div>
          </div>
        </div>
        <script>
          vegaEmbed('#vis-7-2', {"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "description": "AutoVis papers: evaluation-type detection, GraphicsReplicabilityStamp distribution (artifact proxy), and a simple interdisciplinarity heuristic.", "data": {"url": "https://raw.githubusercontent.com/demoPlz/mini-template/main/studio/dataset.csv", "format": {"type": "csv"}}, "transform": [{"filter": "test(/automatic vis|automated vis|visualization recommendation|mixed initiative|mixed-initiative|visualization generation|vis generation|agent/i, (datum.AuthorKeywords || '') + ' ' + (datum.Abstract || '') + ' ' + (datum.Title || ''))"}, {"calculate": "test(/user study|user-study|field study|lab study|experiment|participant|human subject|usability|user evaluation|usability study/i, (datum.Abstract||'') + ' ' + (datum.Title||'') + ' ' + (datum.AuthorKeywords||'')) ? 'user study' : test(/case study/i, (datum.Abstract||'') + ' ' + (datum.Title||'') + ' ' + (datum.AuthorKeywords||'')) ? 'case study' : test(/benchmark|benchmarking|evaluation framework|evaluation methodology/i, (datum.Abstract||'') + ' ' + (datum.Title||'') + ' ' + (datum.AuthorKeywords||'')) ? 'benchmark' : test(/qualitative|interview|focus group|thematic|ethnography/i, (datum.Abstract||'') + ' ' + (datum.Title||'') + ' ' + (datum.AuthorKeywords||'')) ? 'qualitative' : test(/quantitative|statistic|anova|t-test|p-value|measurement|metric|quantitative/i, (datum.Abstract||'') + ' ' + (datum.Title||'') + ' ' + (datum.AuthorKeywords||'')) ? 'quantitative' : 'other'", "as": "EvalType"}, {"calculate": "datum.GraphicsReplicabilityStamp && datum.GraphicsReplicabilityStamp !== '' ? datum.GraphicsReplicabilityStamp : 'None'", "as": "RepStamp"}, {"calculate": "(test(/computer|cs|computer science|dept of computer|department of computer/i, datum.AuthorAffiliation) && test(/physics|psycholog|biolog|medicine|statist|design|sociolog|economics|engineering|biomedical|humanit|chemistry|material|mathematics|cognitive/i, datum.AuthorAffiliation)) ? 'Interdisciplinary' : 'Not Interdisciplinary'", "as": "Interdisciplinary"}], "vconcat": [{"title": "Detected evaluation types in AutoVis papers (heuristic keyword mapping)", "mark": {"type": "bar", "tooltip": true}, "width": 480, "height": 160, "encoding": {"x": {"field": "EvalType", "type": "nominal", "axis": {"labelAngle": -20, "labelExpr": "datum.label"}}, "y": {"aggregate": "count", "type": "quantitative", "title": "# papers"}, "color": {"field": "EvalType", "type": "nominal", "legend": null}}}, {"title": "GraphicsReplicabilityStamp distribution (artifact/reproducibility proxy)", "mark": {"type": "bar", "tooltip": true}, "width": 480, "height": 140, "encoding": {"x": {"field": "RepStamp", "type": "nominal", "axis": {"labelAngle": -20}}, "y": {"aggregate": "count", "type": "quantitative", "title": "# papers"}, "color": {"field": "RepStamp", "type": "nominal", "legend": null}}}, {"title": "Interdisciplinarity heuristic (presence of CS + other domain in affiliations)", "mark": {"type": "bar", "tooltip": true}, "width": 480, "height": 120, "encoding": {"x": {"field": "Interdisciplinary", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative", "title": "# papers"}, "color": {"field": "Interdisciplinary", "type": "nominal", "legend": null}}}], "config": {"view": {"stroke": "transparent"}, "axis": {"labelFontSize": 11, "titleFontSize": 12}, "title": {"fontSize": 13}}}, {
            actions: false,
            renderer: 'canvas',
            config: {}
          })
          .catch(console.error);
        </script>
      </div>
    </div>
  </div>
</section>
<script>
document.addEventListener('DOMContentLoaded', function () {
  const toc = document.getElementById('toc');
  if (!toc) return;

  const headers = document.querySelectorAll('article h2, article h3');
  headers.forEach(h => {
    let id = h.textContent.trim().replace(/\s+/g, '-').toLowerCase();
    h.setAttribute('id', id);

    const link = document.createElement('a');
    link.href = '#' + id;
    link.textContent = h.textContent;
    link.className = (h.tagName === 'H2'
      ? 'block font-semibold mb-1'      : 'block ml-4 text-gray-500') + ' hover:text-primary-600';

    toc.appendChild(link);
  });
});
</script>
    </article>
  </main>
  <footer class='border-t mt-12 py-6 text-center text-sm text-gray-500'>
    © 2025 Agentic VIS
  </footer>
  <script>
  document.addEventListener('DOMContentLoaded', function () {
  const tocList = document.getElementById('toc-list');
  const headers = document.querySelectorAll('article h2, article h3');
  const links = [];

  headers.forEach((h, idx) => {
    let id = h.textContent.trim().replace(/\s+/g, '-').toLowerCase() + '-' + idx;
    h.setAttribute('id', id);

    const li = document.createElement('li');
    li.className = 'flex items-center space-x-2';

    const dot = document.createElement('span');
    dot.className = 'w-2 h-2 rounded-full border border-gray-300';
    li.appendChild(dot);

    const link = document.createElement('a');
    link.href = '#' + id;

    const text = h.textContent.trim();
    link.textContent = text.length > 40 ? text.slice(0, 37) + '…' : text;
    link.title = text;

    link.className = 'block truncate text-gray-400 hover:text-gray-600';
    if (h.tagName === 'H3') {
      link.className += ' ml-4';
    }

    link.addEventListener('click', function (e) {
      e.preventDefault();
      const target = document.getElementById(id);
      if (target) {
        const y = target.getBoundingClientRect().top + window.scrollY - 100;
        window.scrollTo({ top: y, behavior: 'smooth' });
      }
    });

    li.appendChild(link);
    tocList.appendChild(li);
    links.push({id, link, el: h, dot});
  });

  function onScroll() {
    let scrollPos = document.documentElement.scrollTop || document.body.scrollTop;
    let current;
    links.forEach(item => {
      if (item.el.offsetTop - 120 <= scrollPos) {
        current = item;
      }
    });
    links.forEach(item => {
      item.link.classList.remove('font-semibold', 'text-black');
      item.link.classList.add('text-gray-400');
      item.dot.className = 'w-2 h-2 rounded-full border border-gray-300';
    });
    if (current) {
      current.link.classList.remove('text-gray-400');
      current.link.classList.add('font-semibold', 'text-black');
      current.dot.className = 'w-2 h-2 rounded-full bg-black';
    }
  }
  window.addEventListener('scroll', onScroll);
  onScroll();
});
</script>
<script>
window.addEventListener('scroll', function () {
  const docHeight = document.documentElement.scrollHeight - window.innerHeight;
  const scrollTop = window.scrollY || document.documentElement.scrollTop;
  const progress = (scrollTop / docHeight) * 100;
  document.getElementById('progress-bar').style.width = progress + '%';
});
</script></body>
</html>