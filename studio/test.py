import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.offline as pyo
from collections import Counter
import numpy as np
from datetime import datetime
import re

# è®¾ç½®plotlyç¦»çº¿æ¨¡å¼
pyo.init_notebook_mode(connected=True)

# ============================================================================
# æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
# ============================================================================

def load_and_preprocess_data():
    """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
    print("æ­£åœ¨åŠ è½½æ•°æ®...")
    
    # è¯»å–æ•°æ®
    df = pd.read_csv("dataset.csv")
    
    # è½¬æ¢å¹´ä»½ä¸ºdatetime
    df["Year"] = pd.to_datetime(df["Year"], format='%Y')
    
    # å¤„ç†ç¼ºå¤±å€¼
    df = df.fillna({
        'CitationCount_CrossRef': 0,
        'CitationCount_Aminer': 0,
        'AuthorKeywords': '',
        'Authors': '',
        'Title': '',
        'Conference': ''
    })
    
    print(f"æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
    print(f"å¹´ä»½èŒƒå›´: {df['Year'].min().year} - {df['Year'].max().year}")
    
    return df

# ============================================================================
# Key Research Trends åˆ†æ
# ============================================================================

def analyze_research_trends(df):
    """åˆ†æç ”ç©¶è¶‹åŠ¿"""
    print("\n=== åˆ†æç ”ç©¶è¶‹åŠ¿ ===")
    
    # 1. å¹´åº¦å‘è¡¨é‡è¶‹åŠ¿
    yearly_publications = df.groupby(df['Year'].dt.year).size().reset_index(name='count')
    
    fig1 = px.line(yearly_publications, x='Year', y='count',
                   title='ğŸ“ˆ å¹´åº¦å‘è¡¨é‡è¶‹åŠ¿',
                   labels={'Year': 'å¹´ä»½', 'count': 'å‘è¡¨æ•°é‡'},
                   markers=True)
    fig1.update_layout(
        template='plotly_white',
        height=500,
        showlegend=False
    )
    fig1.show()
    
    # 2. å…³é”®è¯è¶‹åŠ¿åˆ†æ
    def extract_keywords(keywords_str):
        """æå–å…³é”®è¯"""
        if pd.isna(keywords_str) or keywords_str == '':
            return []
        # åˆ†å‰²å…³é”®è¯ï¼ˆå‡è®¾ç”¨åˆ†å·æˆ–é€—å·åˆ†éš”ï¼‰
        keywords = re.split(r'[;,]\s*', str(keywords_str))
        return [kw.strip().lower() for kw in keywords if kw.strip()]
    
    # æå–æ‰€æœ‰å…³é”®è¯
    all_keywords = []
    for keywords in df['AuthorKeywords']:
        all_keywords.extend(extract_keywords(keywords))
    
    # ç»Ÿè®¡å…³é”®è¯é¢‘ç‡
    keyword_counts = Counter(all_keywords)
    top_keywords = dict(keyword_counts.most_common(15))
    
    # å…³é”®è¯é¢‘ç‡æŸ±çŠ¶å›¾
    fig2 = px.bar(x=list(top_keywords.keys()), y=list(top_keywords.values()),
                  title='ğŸ”‘ çƒ­é—¨å…³é”®è¯é¢‘ç‡',
                  labels={'x': 'å…³é”®è¯', 'y': 'å‡ºç°æ¬¡æ•°'},
                  color=list(top_keywords.values()),
                  color_continuous_scale='viridis')
    fig2.update_layout(
        template='plotly_white',
        height=500,
        xaxis_tickangle=-45
    )
    fig2.show()
    
    # 3. å…³é”®è¯éšæ—¶é—´å˜åŒ–è¶‹åŠ¿
    keyword_trends = {}
    for year in df['Year'].dt.year.unique():
        year_data = df[df['Year'].dt.year == year]
        year_keywords = []
        for keywords in year_data['AuthorKeywords']:
            year_keywords.extend(extract_keywords(keywords))
        keyword_trends[year] = Counter(year_keywords)
    
    # é€‰æ‹©å‰5ä¸ªå…³é”®è¯è¿›è¡Œè¶‹åŠ¿åˆ†æ
    top_5_keywords = list(top_keywords.keys())[:5]
    
    trend_data = []
    for keyword in top_5_keywords:
        for year in sorted(keyword_trends.keys()):
            count = keyword_trends[year].get(keyword, 0)
            trend_data.append({'Year': year, 'Keyword': keyword, 'Count': count})
    
    trend_df = pd.DataFrame(trend_data)
    
    fig3 = px.line(trend_df, x='Year', y='Count', color='Keyword',
                   title='ğŸ“Š å…³é”®è¯éšæ—¶é—´å˜åŒ–è¶‹åŠ¿',
                   labels={'Year': 'å¹´ä»½', 'Count': 'å‡ºç°æ¬¡æ•°', 'Keyword': 'å…³é”®è¯'})
    fig3.update_layout(
        template='plotly_white',
        height=500
    )
    fig3.show()
    
    return yearly_publications, top_keywords, trend_df

# ============================================================================
# Key Authors åˆ†æ
# ============================================================================

def analyze_key_authors(df):
    """åˆ†æå…³é”®ä½œè€…"""
    print("\n=== åˆ†æå…³é”®ä½œè€… ===")
    
    # 1. æå–ä½œè€…ä¿¡æ¯
    def extract_authors(authors_str):
        """æå–ä½œè€…å§“å"""
        if pd.isna(authors_str) or authors_str == '':
            return []
        # åˆ†å‰²ä½œè€…ï¼ˆå‡è®¾ç”¨åˆ†å·æˆ–é€—å·åˆ†éš”ï¼‰
        authors = re.split(r'[;,]\s*', str(authors_str))
        return [author.strip() for author in authors if author.strip()]
    
    # ç»Ÿè®¡ä½œè€…å‘è¡¨é‡
    all_authors = []
    for authors in df['Authors']:
        all_authors.extend(extract_authors(authors))
    
    author_counts = Counter(all_authors)
    top_authors = dict(author_counts.most_common(20))
    
    # ä½œè€…å‘è¡¨é‡æŸ±çŠ¶å›¾
    fig4 = px.bar(x=list(top_authors.keys()), y=list(top_authors.values()),
                  title='ğŸ‘¥ ä½œè€…å‘è¡¨é‡æ’å',
                  labels={'x': 'ä½œè€…', 'y': 'å‘è¡¨æ•°é‡'},
                  color=list(top_authors.values()),
                  color_continuous_scale='plasma')
    fig4.update_layout(
        template='plotly_white',
        height=600,
        xaxis_tickangle=-45
    )
    fig4.show()
    
    # 2. ä½œè€…å¼•ç”¨é‡åˆ†æ
    author_citations = {}
    for idx, row in df.iterrows():
        authors = extract_authors(row['Authors'])
        citations = row['CitationCount_CrossRef']
        for author in authors:
            if author in author_citations:
                author_citations[author] += citations
            else:
                author_citations[author] = citations
    
    # æŒ‰å¼•ç”¨é‡æ’åº
    top_cited_authors = dict(sorted(author_citations.items(), 
                                   key=lambda x: x[1], reverse=True)[:15])
    
    # ä½œè€…å¼•ç”¨é‡æŸ±çŠ¶å›¾
    fig5 = px.bar(x=list(top_cited_authors.keys()), y=list(top_cited_authors.values()),
                  title='ğŸ“š ä½œè€…å¼•ç”¨é‡æ’å',
                  labels={'x': 'ä½œè€…', 'y': 'æ€»å¼•ç”¨é‡'},
                  color=list(top_cited_authors.values()),
                  color_continuous_scale='inferno')
    fig5.update_layout(
        template='plotly_white',
        height=600,
        xaxis_tickangle=-45
    )
    fig5.show()
    
    # 3. ä½œè€…åˆä½œç½‘ç»œåˆ†æ
    collaboration_data = []
    for authors in df['Authors']:
        author_list = extract_authors(authors)
        if len(author_list) > 1:
            for i in range(len(author_list)):
                for j in range(i+1, len(author_list)):
                    collaboration_data.append({
                        'Author1': author_list[i],
                        'Author2': author_list[j]
                    })
    
    if collaboration_data:
        collaboration_df = pd.DataFrame(collaboration_data)
        collaboration_counts = collaboration_df.groupby(['Author1', 'Author2']).size().reset_index(name='count')
        top_collaborations = collaboration_counts.nlargest(10, 'count')
        
        # åˆä½œç½‘ç»œå›¾
        fig6 = px.scatter(top_collaborations, x='Author1', y='Author2', size='count',
                         title='ğŸ¤ ä½œè€…åˆä½œç½‘ç»œï¼ˆå‰10å¯¹ï¼‰',
                         labels={'Author1': 'ä½œè€…1', 'Author2': 'ä½œè€…2', 'count': 'åˆä½œæ¬¡æ•°'},
                         color='count',
                         color_continuous_scale='viridis')
        fig6.update_layout(
            template='plotly_white',
            height=500
        )
        fig6.show()
    
    return top_authors, top_cited_authors, collaboration_data

# ============================================================================
# ç»¼åˆåˆ†æå’Œå¯è§†åŒ–
# ============================================================================

def create_comprehensive_dashboard(df):
    """åˆ›å»ºç»¼åˆåˆ†æä»ªè¡¨æ¿"""
    print("\n=== åˆ›å»ºç»¼åˆåˆ†æä»ªè¡¨æ¿ ===")
    
    # åˆ›å»ºå­å›¾
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('å¹´åº¦å‘è¡¨é‡è¶‹åŠ¿', 'çƒ­é—¨å…³é”®è¯', 'ä½œè€…å‘è¡¨é‡', 'ä½œè€…å¼•ç”¨é‡'),
        specs=[[{"type": "scatter"}, {"type": "bar"}],
               [{"type": "bar"}, {"type": "bar"}]]
    )
    
    # 1. å¹´åº¦å‘è¡¨é‡
    yearly_pubs = df.groupby(df['Year'].dt.year).size()
    fig.add_trace(
        go.Scatter(x=yearly_pubs.index, y=yearly_pubs.values, 
                  mode='lines+markers', name='å‘è¡¨é‡'),
        row=1, col=1
    )
    
    # 2. çƒ­é—¨å…³é”®è¯
    all_keywords = []
    for keywords in df['AuthorKeywords']:
        if pd.notna(keywords) and keywords != '':
            keywords_list = re.split(r'[;,]\s*', str(keywords))
            all_keywords.extend([kw.strip().lower() for kw in keywords_list if kw.strip()])
    
    keyword_counts = Counter(all_keywords)
    top_keywords = dict(keyword_counts.most_common(10))
    
    fig.add_trace(
        go.Bar(x=list(top_keywords.keys()), y=list(top_keywords.values()),
               name='å…³é”®è¯é¢‘ç‡'),
        row=1, col=2
    )
    
    # 3. ä½œè€…å‘è¡¨é‡
    all_authors = []
    for authors in df['Authors']:
        if pd.notna(authors) and authors != '':
            authors_list = re.split(r'[;,]\s*', str(authors))
            all_authors.extend([author.strip() for author in authors_list if author.strip()])
    
    author_counts = Counter(all_authors)
    top_authors = dict(author_counts.most_common(10))
    
    fig.add_trace(
        go.Bar(x=list(top_authors.keys()), y=list(top_authors.values()),
               name='ä½œè€…å‘è¡¨é‡'),
        row=2, col=1
    )
    
    # 4. ä½œè€…å¼•ç”¨é‡
    author_citations = {}
    for idx, row in df.iterrows():
        if pd.notna(row['Authors']) and row['Authors'] != '':
            authors = re.split(r'[;,]\s*', str(row['Authors']))
            citations = row['CitationCount_CrossRef']
            for author in authors:
                author = author.strip()
                if author:
                    author_citations[author] = author_citations.get(author, 0) + citations
    
    top_cited = dict(sorted(author_citations.items(), 
                           key=lambda x: x[1], reverse=True)[:10])
    
    fig.add_trace(
        go.Bar(x=list(top_cited.keys()), y=list(top_cited.values()),
               name='ä½œè€…å¼•ç”¨é‡'),
        row=2, col=2
    )
    
    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        title_text="ğŸ“Š ç ”ç©¶è¶‹åŠ¿ä¸ä½œè€…åˆ†æç»¼åˆä»ªè¡¨æ¿",
        height=800,
        template='plotly_white',
        showlegend=False
    )
    
    # æ›´æ–°xè½´æ ‡ç­¾è§’åº¦
    fig.update_xaxes(tickangle=-45, row=1, col=2)
    fig.update_xaxes(tickangle=-45, row=2, col=1)
    fig.update_xaxes(tickangle=-45, row=2, col=2)
    
    fig.show()
    
    return fig

# ============================================================================
# é«˜çº§åˆ†æåŠŸèƒ½
# ============================================================================

def advanced_analysis(df):
    """é«˜çº§åˆ†æåŠŸèƒ½"""
    print("\n=== é«˜çº§åˆ†æ ===")
    
    # 1. ä¼šè®®åˆ†æ
    conference_stats = df.groupby('Conference').agg({
        'CitationCount_CrossRef': ['mean', 'sum', 'count']
    }).round(2)
    conference_stats.columns = ['å¹³å‡å¼•ç”¨é‡', 'æ€»å¼•ç”¨é‡', 'å‘è¡¨æ•°é‡']
    conference_stats = conference_stats.sort_values('å‘è¡¨æ•°é‡', ascending=False)
    
    print("ä¼šè®®ç»Ÿè®¡:")
    print(conference_stats.head(10))
    
    # ä¼šè®®å‘è¡¨é‡å¯è§†åŒ–
    fig7 = px.bar(conference_stats.head(10), x=conference_stats.head(10).index, 
                  y='å‘è¡¨æ•°é‡',
                  title='ğŸ›ï¸ å„ä¼šè®®å‘è¡¨é‡',
                  labels={'x': 'ä¼šè®®', 'y': 'å‘è¡¨æ•°é‡'},
                  color='å¹³å‡å¼•ç”¨é‡',
                  color_continuous_scale='viridis')
    fig7.update_layout(
        template='plotly_white',
        height=500,
        xaxis_tickangle=-45
    )
    fig7.show()
    
    # 2. å¼•ç”¨é‡åˆ†å¸ƒåˆ†æ
    fig8 = px.histogram(df, x='CitationCount_CrossRef', nbins=30,
                       title='ğŸ“ˆ å¼•ç”¨é‡åˆ†å¸ƒ',
                       labels={'CitationCount_CrossRef': 'å¼•ç”¨é‡', 'count': 'è®ºæ–‡æ•°é‡'})
    fig8.update_layout(
        template='plotly_white',
        height=500
    )
    fig8.show()
    
    # 3. é«˜å¼•ç”¨è®ºæ–‡åˆ†æ
    high_cited = df.nlargest(10, 'CitationCount_CrossRef')[['Title', 'Authors', 'Year', 'CitationCount_CrossRef']]
    
    print("\né«˜å¼•ç”¨è®ºæ–‡:")
    for idx, row in high_cited.iterrows():
        print(f"{row['Year'].year}: {row['Title'][:50]}... (å¼•ç”¨é‡: {row['CitationCount_CrossRef']})")
    
    return conference_stats, high_cited

# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ•°æ®åˆ†æ...")
    
    # åŠ è½½æ•°æ®
    df = load_and_preprocess_data()
    
    # ç ”ç©¶è¶‹åŠ¿åˆ†æ
    yearly_pubs, top_keywords, keyword_trends = analyze_research_trends(df)
    
    # å…³é”®ä½œè€…åˆ†æ
    top_authors, top_cited_authors, collaborations = analyze_key_authors(df)
    
    # ç»¼åˆä»ªè¡¨æ¿
    dashboard = create_comprehensive_dashboard(df)
    
    # é«˜çº§åˆ†æ
    conference_stats, high_cited_papers = advanced_analysis(df)
    
    print("\nâœ… åˆ†æå®Œæˆï¼")
    print(f"ğŸ“Š å…±åˆ†æäº† {len(df)} ç¯‡è®ºæ–‡")
    print(f"ğŸ‘¥ æ¶‰åŠ {len(set([author for authors in df['Authors'] for author in str(authors).split(';') if author.strip()]))} ä½ä½œè€…")
    print(f"ğŸ”‘ åŒ…å« {len(set([kw for keywords in df['AuthorKeywords'] for kw in str(keywords).split(';') if kw.strip()]))} ä¸ªå…³é”®è¯")
    
    return {
        'data': df,
        'yearly_publications': yearly_pubs,
        'top_keywords': top_keywords,
        'keyword_trends': keyword_trends,
        'top_authors': top_authors,
        'top_cited_authors': top_cited_authors,
        'collaborations': collaborations,
        'conference_stats': conference_stats,
        'high_cited_papers': high_cited_papers
    }

if __name__ == "__main__":
    # è¿è¡Œåˆ†æ
    results = main()